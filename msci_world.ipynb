{
  "cells": [
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-04-08T08:54:55.862323Z",
          "start_time": "2025-04-08T08:54:55.857892Z"
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "import hashlib\n",
        "import os\n",
        "import warnings\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "import pytz\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# ------------------ CONFIGURATION ------------------\n",
        "json_data_dir = './download/data'\n",
        "output_dir = './out/'\n",
        "\n",
        "marker_dot_size = 0\n",
        "\n",
        "## -------- some filters to remove entries from the data --------\n",
        "# e.g. 'APPLE INC', 'Name ABC'\n",
        "remove_by_name = []\n",
        "# e.g. 'AAPL', 'MSFT'\n",
        "remove_by_ticker = []\n",
        "# e.g. 'Versorger', 'Immobilien', 'Energie', 'Materialien', 'Telekommunikationsdienste'\n",
        "remove_by_sector = []\n",
        "# 'Vereinigte Staaten', 'Deutschland', 'Frankreich'\n",
        "remove_by_standort = []\n",
        "# ---------------------------------------------------\n",
        "\n",
        "# -- some checks\n",
        "if not os.path.exists(json_data_dir):\n",
        "    raise FileNotFoundError(f\"File not found: {json_data_dir}\")\n",
        "\n",
        "# create output directory if not exists\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "print(f\"Output directory: {output_dir}\")\n"
      ],
      "id": "5f9fb6365fbe6827",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-04-08T08:55:01.079417Z",
          "start_time": "2025-04-08T08:54:59.597757Z"
        }
      },
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# create a hashmap for each day containing the df\n",
        "df_by_stichtag = {}\n",
        "\n",
        "# iterate over all files in the data directory\n",
        "for json_file in os.listdir(json_data_dir):\n",
        "    if not json_file.endswith('.json'):\n",
        "        continue\n",
        "\n",
        "    # Load JSON data\n",
        "    with open(os.path.join(json_data_dir, json_file), 'r', encoding='utf-8') as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    # Extract the aaData array\n",
        "    aaData = data['aaData']\n",
        "\n",
        "    # Define the column names\n",
        "    columns = [\n",
        "        'Emittententicker', 'Name', 'Sektor', 'Anlageklasse', 'Marktwert',\n",
        "        'Gewichtung (%)', 'Nominalwert', 'Nominale', 'Kurs', 'Standort',\n",
        "        'Börse', 'Marktwährung'\n",
        "    ]\n",
        "    # Create a list of rows\n",
        "    rows = []\n",
        "    for item in aaData:\n",
        "        row = [\n",
        "            item[0],  # Emittententicker\n",
        "            item[1],  # Name\n",
        "            item[2],  # Sektor\n",
        "            item[3],  # Anlageklasse\n",
        "            item[4]['raw'],  # Marktwert\n",
        "            item[5]['raw'],  # Gewichtung (%)\n",
        "            item[6]['raw'],  # Nominalwert\n",
        "            item[7]['raw'],  # Nominale\n",
        "            item[9]['raw'],  # Kurs\n",
        "            item[10],  # Standort\n",
        "            item[11],  # Börse\n",
        "            item[12]  # Marktwährung\n",
        "        ]\n",
        "        rows.append(row)\n",
        "\n",
        "    # Create DataFrame\n",
        "    df = pd.DataFrame(rows, columns=columns)\n",
        "\n",
        "    stichtag = json_file.split('.')[0]\n",
        "\n",
        "    df_by_stichtag[stichtag] = df\n",
        "\n",
        "print(f\"Loaded {len(df_by_stichtag)} dataframes\")\n",
        "\n",
        "# # find the latest entry in the df_by_stichtag by converting the keys to datetime\n",
        "latest_stichtag = max(df_by_stichtag.keys(), key=lambda x: pd.to_datetime(x, format='%Y%m%d'))\n",
        "print(f\"Latest stichtag: {latest_stichtag}\")\n",
        "\n",
        "#df_by_stichtag"
      ],
      "id": "9ef0cfb17f647c0b",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-04-07T07:20:23.859961Z",
          "start_time": "2025-04-07T07:20:23.852687Z"
        }
      },
      "cell_type": "code",
      "source": [
        "def get_active_filters_headline():\n",
        "    filters = []\n",
        "    if remove_by_name:\n",
        "        filters.append(f\"Name: {', '.join(remove_by_name)}\")\n",
        "    if remove_by_ticker:\n",
        "        filters.append(f\"Ticker: {', '.join(remove_by_ticker)}\")\n",
        "    if remove_by_sector:\n",
        "        filters.append(f\"Sektor: {', '.join(remove_by_sector)}\")\n",
        "    if remove_by_standort:\n",
        "        filters.append(f\"Standort: {', '.join(remove_by_standort)}\")\n",
        "\n",
        "    return 'filtered: [' +  ' | '.join(filters) + ']' if filters else 'no filters applied'\n",
        "\n",
        "# remove entries by \"remove_\" lists\n",
        "for stichtag, df in df_by_stichtag.items():\n",
        "    # Remove entries by name\n",
        "    for name in remove_by_name:\n",
        "        df = df[~df['Name'].str.contains(name, na=False)]\n",
        "\n",
        "    # Remove entries by ticker\n",
        "    for ticker in remove_by_ticker:\n",
        "        df = df[~df['Emittententicker'].str.contains(ticker, na=False)]\n",
        "\n",
        "    # Remove entries by sector\n",
        "    for sector in remove_by_sector:\n",
        "        df = df[~df['Sektor'].str.contains(sector, na=False)]\n",
        "\n",
        "    # Remove entries by standort\n",
        "    for standort in remove_by_standort:\n",
        "        df = df[~df['Standort'].str.contains(standort, na=False)]\n",
        "\n",
        "    # Update the DataFrame in the dictionary\n",
        "    df_by_stichtag[stichtag] = df\n",
        "\n",
        "print(f\"Active filters: {get_active_filters_headline()}\")"
      ],
      "id": "efdc7d0dde212aca",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-04-07T07:20:25.844824Z",
          "start_time": "2025-04-07T07:20:23.933990Z"
        }
      },
      "cell_type": "code",
      "source": [
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "line_styles = ['-', '--', '-.', ':', ' ', '', 'solid', 'dashed', 'dashdot', 'dotted']\n",
        "line_style_cycle = iter(line_styles)\n",
        "\n",
        "# Create a dictionary to store the dates and corresponding aggregated \"Gewichtung (%)\" values for each Standort\n",
        "standort_entries = {}\n",
        "\n",
        "# Iterate over the DataFrames to aggregate the \"Gewichtung (%)\" values for each Standort\n",
        "for date, df in df_by_stichtag.items():\n",
        "    for standort in df['Standort'].unique():\n",
        "        if standort not in standort_entries:\n",
        "            standort_entries[standort] = {'dates': [], 'weights': []}\n",
        "\n",
        "        # Sum the \"Gewichtung (%)\" for the current Standort\n",
        "        total_weight = df[df['Standort'] == standort]['Gewichtung (%)'].sum()\n",
        "\n",
        "        standort_entries[standort]['dates'].append(date)\n",
        "        standort_entries[standort]['weights'].append(total_weight)\n",
        "\n",
        "# Plot the data\n",
        "plt.figure(figsize=(12, 8))\n",
        "for standort, data in standort_entries.items():\n",
        "    # Create a DataFrame for the current Standort\n",
        "    standort_df = pd.DataFrame({'Date': data['dates'], 'Gewichtung (%)': data['weights']})\n",
        "\n",
        "    # Convert the 'Date' column to datetime, invalid parsing will be set as NaT\n",
        "    standort_df['Date'] = pd.to_datetime(standort_df['Date'], errors='coerce')\n",
        "\n",
        "    # Drop rows with NaT values in the 'Date' column\n",
        "    standort_df = standort_df.dropna(subset=['Date'])\n",
        "\n",
        "    # Sort the DataFrame by date\n",
        "    standort_df = standort_df.sort_values('Date')\n",
        "\n",
        "    # get random line style\n",
        "    random_line_style = random.choice(line_styles)\n",
        "\n",
        "    # Plot the data for the current Standort\n",
        "    plt.plot(standort_df['Date'], standort_df['Gewichtung (%)'], marker='o', markersize=marker_dot_size, label=standort, linestyle=random_line_style)\n",
        "\n",
        "plt.title(f\"Total Gewichtung (%) Over Time by Standort | {get_active_filters_headline()}\")\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Total Gewichtung (%)')\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "plt.grid(True)\n",
        "# if filters\n",
        "# create a unique filename based on the filters\n",
        "filters_hash = hashlib.md5(get_active_filters_headline().encode()).hexdigest()\n",
        "plt.savefig(os.path.join(output_dir, f'gewichtung_by_standort_{filters_hash}.png'), dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ],
      "id": "67d6865ec7f92c7b",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-04-07T07:20:27.026786Z",
          "start_time": "2025-04-07T07:20:25.920232Z"
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import hashlib\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "\n",
        "# Create a dictionary to store the dates and corresponding aggregated \"Gewichtung (%)\" values for each Standort\n",
        "standort_entries = {}\n",
        "\n",
        "# Iterate over the DataFrames to aggregate the \"Gewichtung (%)\" values for each Standort\n",
        "for date, df in df_by_stichtag.items():\n",
        "    for standort in df['Standort'].unique():\n",
        "        if standort not in standort_entries:\n",
        "            standort_entries[standort] = {'dates': [], 'weights': []}\n",
        "\n",
        "        # Sum the \"Gewichtung (%)\" for the current Standort\n",
        "        total_weight = df[df['Standort'] == standort]['Gewichtung (%)'].sum()\n",
        "\n",
        "        standort_entries[standort]['dates'].append(date)\n",
        "        standort_entries[standort]['weights'].append(total_weight)\n",
        "\n",
        "# Create a DataFrame for Plotly\n",
        "plotly_data = []\n",
        "for standort, data in standort_entries.items():\n",
        "    for date, weight in zip(data['dates'], data['weights']):\n",
        "        plotly_data.append({'Date': date, 'Gewichtung (%)': weight, 'Standort': standort})\n",
        "\n",
        "plotly_df = pd.DataFrame(plotly_data)\n",
        "\n",
        "# Convert the 'Date' column to datetime\n",
        "plotly_df['Date'] = pd.to_datetime(plotly_df['Date'], errors='coerce')\n",
        "\n",
        "# Drop rows with NaT values in the 'Date' column\n",
        "plotly_df = plotly_df.dropna(subset=['Date'])\n",
        "\n",
        "# Sort the DataFrame by date\n",
        "plotly_df = plotly_df.sort_values('Date')\n",
        "\n",
        "# Create the Plotly line chart\n",
        "fig = px.line(plotly_df, x='Date', y='Gewichtung (%)', color='Standort', title=f\"Total Gewichtung (%) Over Time by Standort | {get_active_filters_headline()}\", category_orders={'Standort': sorted(plotly_df['Standort'].unique())})\n",
        "\n",
        "# Save the Plotly chart as an HTML file\n",
        "filters_hash = hashlib.md5(get_active_filters_headline().encode()).hexdigest()\n",
        "output_file = os.path.join(output_dir, f'gewichtung_by_standort_{filters_hash}.html')\n",
        "fig.write_html(output_file)\n",
        "\n",
        "print(f\"Interactive Plotly chart saved to {output_file}\")"
      ],
      "id": "1775cd034f53f103",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-04-07T07:20:28.021632Z",
          "start_time": "2025-04-07T07:20:27.181933Z"
        }
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Identify the top 10 entries by \"Gewichtung (%)\" in the 20250131 DataFrame\n",
        "top_10_df = df_by_stichtag[latest_stichtag].nlargest(10, 'Gewichtung (%)')\n",
        "\n",
        "# Create a dictionary to store the dates and corresponding \"Gewichtung (%)\" values for each top entry\n",
        "top_entries = {ticker: {'dates': [], 'weights': []} for ticker in top_10_df['Name']}\n",
        "\n",
        "# Iterate over the DataFrames to extract the \"Gewichtung (%)\" values for the top 10 entries\n",
        "for date, df in df_by_stichtag.items():\n",
        "    for ticker in top_entries.keys():\n",
        "        row = df[df['Name'] == ticker]\n",
        "        if not row.empty:\n",
        "            top_entries[ticker]['dates'].append(date)\n",
        "            top_entries[ticker]['weights'].append(row['Gewichtung (%)'].values[0])\n",
        "\n",
        "# Plot the data\n",
        "plt.figure(figsize=(12, 8))\n",
        "for ticker, data in top_entries.items():\n",
        "    # Create a DataFrame for the current ticker\n",
        "    ticker_df = pd.DataFrame({'Date': data['dates'], 'Gewichtung (%)': data['weights']})\n",
        "\n",
        "    # Convert the 'Date' column to datetime, invalid parsing will be set as NaT\n",
        "    ticker_df['Date'] = pd.to_datetime(ticker_df['Date'], errors='coerce')\n",
        "\n",
        "    # Drop rows with NaT values in the 'Date' column\n",
        "    ticker_df = ticker_df.dropna(subset=['Date'])\n",
        "\n",
        "    # Sort the DataFrame by date\n",
        "    ticker_df = ticker_df.sort_values('Date')\n",
        "\n",
        "    # Plot the data for the current ticker\n",
        "    plt.plot(ticker_df['Date'], ticker_df['Gewichtung (%)'], marker='o', markersize=marker_dot_size, label=ticker)\n",
        "\n",
        "plt.title(f\"Gewichtung (%) Over Time for Top 10 Entries on {latest_stichtag} | {get_active_filters_headline()}\")\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Gewichtung (%)')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "# create a unique filename based on the filters\n",
        "filters_hash = hashlib.md5(get_active_filters_headline().encode()).hexdigest()\n",
        "plt.savefig(os.path.join(output_dir, f'gewichtung_top_10_{latest_stichtag}_{filters_hash}.png'), dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ],
      "id": "2beddf9eba45e1dc",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-04-07T07:20:28.772702Z",
          "start_time": "2025-04-07T07:20:28.200229Z"
        }
      },
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "\n",
        "# Identify the top 10 entries by \"Gewichtung (%)\" in the latest DataFrame\n",
        "top_10_df = df_by_stichtag[latest_stichtag].nlargest(10, 'Gewichtung (%)')\n",
        "\n",
        "# Create a dictionary to store the dates and corresponding \"Gewichtung (%)\" values for each top entry\n",
        "top_entries = {ticker: {'dates': [], 'weights': []} for ticker in top_10_df['Name']}\n",
        "\n",
        "# Iterate over the DataFrames to extract the \"Gewichtung (%)\" values for the top 10 entries\n",
        "for date, df in df_by_stichtag.items():\n",
        "    for ticker in top_entries.keys():\n",
        "        row = df[df['Name'] == ticker]\n",
        "        if not row.empty:\n",
        "            top_entries[ticker]['dates'].append(date)\n",
        "            top_entries[ticker]['weights'].append(row['Gewichtung (%)'].values[0])\n",
        "\n",
        "# Create a DataFrame for Plotly\n",
        "plotly_data = []\n",
        "for ticker, data in top_entries.items():\n",
        "    for date, weight in zip(data['dates'], data['weights']):\n",
        "        plotly_data.append({'Date': date, 'Gewichtung (%)': weight, 'Ticker': ticker})\n",
        "\n",
        "plotly_df = pd.DataFrame(plotly_data)\n",
        "\n",
        "# Convert the 'Date' column to datetime\n",
        "plotly_df['Date'] = pd.to_datetime(plotly_df['Date'], errors='coerce')\n",
        "\n",
        "# Drop rows with NaT values in the 'Date' column\n",
        "plotly_df = plotly_df.dropna(subset=['Date'])\n",
        "\n",
        "# Sort the DataFrame by date\n",
        "plotly_df = plotly_df.sort_values('Date')\n",
        "\n",
        "# Create the Plotly line chart\n",
        "fig = px.line(plotly_df, x='Date', y='Gewichtung (%)', color='Ticker', title=f\"Gewichtung (%) Over Time for Top 10 Entries on {latest_stichtag} | {get_active_filters_headline()}\", category_orders={'Ticker': sorted(plotly_df['Ticker'].unique())})\n",
        "\n",
        "# Save the Plotly chart as an HTML file\n",
        "filters_hash = hashlib.md5(get_active_filters_headline().encode()).hexdigest()\n",
        "output_file = os.path.join(output_dir, f'gewichtung_top_10_{latest_stichtag}_{filters_hash}.html')\n",
        "fig.write_html(output_file)\n",
        "\n",
        "print(f\"Interactive Plotly chart saved to {output_file}\")"
      ],
      "id": "8dbdda6f75b9e287",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-04-07T07:20:29.300625Z",
          "start_time": "2025-04-07T07:20:28.847473Z"
        }
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Extract the corresponding DataFrame\n",
        "most_recent_df = df_by_stichtag[latest_stichtag]\n",
        "\n",
        "# Create a scatter plot of the \"Gewichtung (%)\" values\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.scatter(most_recent_df['Name'], most_recent_df['Gewichtung (%)'], alpha=0.6, s=20)\n",
        "plt.title(f'Gewichtung (%) for the Most Recent Stichtag: {latest_stichtag} | {get_active_filters_headline()}')\n",
        "plt.xlabel('')\n",
        "plt.xticks([])\n",
        "plt.ylabel('Gewichtung (%)')\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "# create a unique filename based on the filters\n",
        "filters_hash = hashlib.md5(get_active_filters_headline().encode()).hexdigest()\n",
        "plt.savefig(os.path.join(output_dir, f'gewichtung_scatter_{latest_stichtag}_{filters_hash}.png'), dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ],
      "id": "f71bbd45dee8fe60",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-04-07T07:20:29.435416Z",
          "start_time": "2025-04-07T07:20:29.375096Z"
        }
      },
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "\n",
        "# Extract the corresponding DataFrame\n",
        "most_recent_df = df_by_stichtag[latest_stichtag]\n",
        "\n",
        "# Create a Plotly scatter plot of the \"Gewichtung (%)\" values\n",
        "fig = px.scatter(most_recent_df, x='Name', y='Gewichtung (%)', title=f'Gewichtung (%) for the Most Recent Stichtag: {latest_stichtag} | {get_active_filters_headline()}')\n",
        "\n",
        "# Save the Plotly chart as an HTML file\n",
        "filters_hash = hashlib.md5(get_active_filters_headline().encode()).hexdigest()\n",
        "output_file = os.path.join(output_dir, f'gewichtung_scatter_{latest_stichtag}_{filters_hash}.html')\n",
        "fig.write_html(output_file)\n",
        "\n",
        "print(f\"Interactive Plotly chart saved to {output_file}\")"
      ],
      "id": "ba3c86919e32216d",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-04-07T07:20:30.450225Z",
          "start_time": "2025-04-07T07:20:29.482295Z"
        }
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Create dictionaries to store the cumulative \"Gewichtung (%)\" values for each date\n",
        "cumulative_weights_top_10 = {}\n",
        "cumulative_weights_top_20 = {}\n",
        "cumulative_weights_top_50 = {}\n",
        "cumulative_weights_top_100 = {}\n",
        "\n",
        "# Iterate over the DataFrames to calculate the cumulative \"Gewichtung (%)\" for the top 20, top 50, and top 100 entries\n",
        "for date, df in df_by_stichtag.items():\n",
        "    # Identify the top 20, top 50, and top 100 entries by \"Gewichtung (%)\"\n",
        "    top_10_df = df.nlargest(10, 'Gewichtung (%)')\n",
        "    top_20_df = df.nlargest(20, 'Gewichtung (%)')\n",
        "    top_50_df = df.nlargest(50, 'Gewichtung (%)')\n",
        "    top_100_df = df.nlargest(100, 'Gewichtung (%)')\n",
        "\n",
        "    # Calculate the cumulative \"Gewichtung (%)\" for the top 20, top 50, and top 100 entries\n",
        "    cumulative_weight_top_10 = top_10_df['Gewichtung (%)'].sum()\n",
        "    cumulative_weight_top_20 = top_20_df['Gewichtung (%)'].sum()\n",
        "    cumulative_weight_top_50 = top_50_df['Gewichtung (%)'].sum()\n",
        "    cumulative_weight_top_100 = top_100_df['Gewichtung (%)'].sum()\n",
        "\n",
        "    # Store the cumulative weights for the current date\n",
        "    cumulative_weights_top_10[date] = cumulative_weight_top_10\n",
        "    cumulative_weights_top_20[date] = cumulative_weight_top_20\n",
        "    cumulative_weights_top_50[date] = cumulative_weight_top_50\n",
        "    cumulative_weights_top_100[date] = cumulative_weight_top_100\n",
        "\n",
        "# Convert the cumulative weights dictionaries to DataFrames\n",
        "cumulative_weights_top_10_df = pd.DataFrame(list(cumulative_weights_top_10.items()),\n",
        "                                            columns=['Date', 'Cumulative Gewichtung (%)'])\n",
        "cumulative_weights_top_20_df = pd.DataFrame(list(cumulative_weights_top_20.items()),\n",
        "                                            columns=['Date', 'Cumulative Gewichtung (%)'])\n",
        "cumulative_weights_top_50_df = pd.DataFrame(list(cumulative_weights_top_50.items()),\n",
        "                                            columns=['Date', 'Cumulative Gewichtung (%)'])\n",
        "cumulative_weights_top_100_df = pd.DataFrame(list(cumulative_weights_top_100.items()),\n",
        "                                             columns=['Date', 'Cumulative Gewichtung (%)'])\n",
        "\n",
        "# Convert the 'Date' columns to datetime, invalid parsing will be set as NaT\n",
        "cumulative_weights_top_10_df['Date'] = pd.to_datetime(cumulative_weights_top_10_df['Date'], errors='coerce')\n",
        "cumulative_weights_top_20_df['Date'] = pd.to_datetime(cumulative_weights_top_20_df['Date'], errors='coerce')\n",
        "cumulative_weights_top_50_df['Date'] = pd.to_datetime(cumulative_weights_top_50_df['Date'], errors='coerce')\n",
        "cumulative_weights_top_100_df['Date'] = pd.to_datetime(cumulative_weights_top_100_df['Date'], errors='coerce')\n",
        "\n",
        "# Drop rows with NaT values in the 'Date' columns\n",
        "cumulative_weights_top_10_df = cumulative_weights_top_10_df.dropna(subset=['Date'])\n",
        "cumulative_weights_top_20_df = cumulative_weights_top_20_df.dropna(subset=['Date'])\n",
        "cumulative_weights_top_50_df = cumulative_weights_top_50_df.dropna(subset=['Date'])\n",
        "cumulative_weights_top_100_df = cumulative_weights_top_100_df.dropna(subset=['Date'])\n",
        "\n",
        "# Sort the DataFrames by date\n",
        "cumulative_weights_top_10_df = cumulative_weights_top_10_df.sort_values('Date')\n",
        "cumulative_weights_top_20_df = cumulative_weights_top_20_df.sort_values('Date')\n",
        "cumulative_weights_top_50_df = cumulative_weights_top_50_df.sort_values('Date')\n",
        "cumulative_weights_top_100_df = cumulative_weights_top_100_df.sort_values('Date')\n",
        "\n",
        "# Plot the cumulative \"Gewichtung (%)\" over time for top 20, top 50, and top 100 entries\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.plot(cumulative_weights_top_10_df['Date'], cumulative_weights_top_10_df['Cumulative Gewichtung (%)'], marker='o',\n",
        "         markersize=marker_dot_size, label='Top 10')\n",
        "plt.plot(cumulative_weights_top_20_df['Date'], cumulative_weights_top_20_df['Cumulative Gewichtung (%)'], marker='o',\n",
        "         markersize=marker_dot_size, label='Top 20')\n",
        "plt.plot(cumulative_weights_top_50_df['Date'], cumulative_weights_top_50_df['Cumulative Gewichtung (%)'], marker='o',\n",
        "         markersize=marker_dot_size, label='Top 50')\n",
        "plt.plot(cumulative_weights_top_100_df['Date'], cumulative_weights_top_100_df['Cumulative Gewichtung (%)'],\n",
        "         markersize=marker_dot_size, marker='o', label='Top 100')\n",
        "\n",
        "plt.title(f\"Cumulative Gewichtung (%) Over Time for Top 10/20/50/100 Entries | {get_active_filters_headline()}\")\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Cumulative Gewichtung (%)')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "# create a unique filename based on the filters\n",
        "filters_hash = hashlib.md5(get_active_filters_headline().encode()).hexdigest()\n",
        "plt.savefig(os.path.join(output_dir, f'gewichtung_cumulative_top_10_20_50_100_{filters_hash}.png'), dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ],
      "id": "eb0b9e3f8cd64165",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-04-07T07:20:30.936065Z",
          "start_time": "2025-04-07T07:20:30.501139Z"
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import hashlib\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "\n",
        "# Create dictionaries to store the cumulative \"Gewichtung (%)\" values for each date\n",
        "cumulative_weights_top_10 = {}\n",
        "cumulative_weights_top_20 = {}\n",
        "cumulative_weights_top_50 = {}\n",
        "cumulative_weights_top_100 = {}\n",
        "\n",
        "# Iterate over the DataFrames to calculate the cumulative \"Gewichtung (%)\" for the top 10, top 20, top 50, and top 100 entries\n",
        "for date, df in df_by_stichtag.items():\n",
        "    # Identify the top 10, top 20, top 50, and top 100 entries by \"Gewichtung (%)\"\n",
        "    top_10_df = df.nlargest(10, 'Gewichtung (%)')\n",
        "    top_20_df = df.nlargest(20, 'Gewichtung (%)')\n",
        "    top_50_df = df.nlargest(50, 'Gewichtung (%)')\n",
        "    top_100_df = df.nlargest(100, 'Gewichtung (%)')\n",
        "\n",
        "    # Calculate the cumulative \"Gewichtung (%)\" for the top 10, top 20, top 50, and top 100 entries\n",
        "    cumulative_weight_top_10 = top_10_df['Gewichtung (%)'].sum()\n",
        "    cumulative_weight_top_20 = top_20_df['Gewichtung (%)'].sum()\n",
        "    cumulative_weight_top_50 = top_50_df['Gewichtung (%)'].sum()\n",
        "    cumulative_weight_top_100 = top_100_df['Gewichtung (%)'].sum()\n",
        "\n",
        "    # Store the cumulative weights for the current date\n",
        "    cumulative_weights_top_10[date] = cumulative_weight_top_10\n",
        "    cumulative_weights_top_20[date] = cumulative_weight_top_20\n",
        "    cumulative_weights_top_50[date] = cumulative_weight_top_50\n",
        "    cumulative_weights_top_100[date] = cumulative_weight_top_100\n",
        "\n",
        "# Convert the cumulative weights dictionaries to DataFrames\n",
        "cumulative_weights_top_10_df = pd.DataFrame(list(cumulative_weights_top_10.items()), columns=['Date', 'Cumulative Gewichtung (%)'])\n",
        "cumulative_weights_top_20_df = pd.DataFrame(list(cumulative_weights_top_20.items()), columns=['Date', 'Cumulative Gewichtung (%)'])\n",
        "cumulative_weights_top_50_df = pd.DataFrame(list(cumulative_weights_top_50.items()), columns=['Date', 'Cumulative Gewichtung (%)'])\n",
        "cumulative_weights_top_100_df = pd.DataFrame(list(cumulative_weights_top_100.items()), columns=['Date', 'Cumulative Gewichtung (%)'])\n",
        "\n",
        "# Convert the 'Date' columns to datetime\n",
        "cumulative_weights_top_10_df['Date'] = pd.to_datetime(cumulative_weights_top_10_df['Date'], errors='coerce')\n",
        "cumulative_weights_top_20_df['Date'] = pd.to_datetime(cumulative_weights_top_20_df['Date'], errors='coerce')\n",
        "cumulative_weights_top_50_df['Date'] = pd.to_datetime(cumulative_weights_top_50_df['Date'], errors='coerce')\n",
        "cumulative_weights_top_100_df['Date'] = pd.to_datetime(cumulative_weights_top_100_df['Date'], errors='coerce')\n",
        "\n",
        "# Drop rows with NaT values in the 'Date' columns\n",
        "cumulative_weights_top_10_df = cumulative_weights_top_10_df.dropna(subset=['Date'])\n",
        "cumulative_weights_top_20_df = cumulative_weights_top_20_df.dropna(subset=['Date'])\n",
        "cumulative_weights_top_50_df = cumulative_weights_top_50_df.dropna(subset=['Date'])\n",
        "cumulative_weights_top_100_df = cumulative_weights_top_100_df.dropna(subset=['Date'])\n",
        "\n",
        "# Sort the DataFrames by date\n",
        "cumulative_weights_top_10_df = cumulative_weights_top_10_df.sort_values('Date')\n",
        "cumulative_weights_top_20_df = cumulative_weights_top_20_df.sort_values('Date')\n",
        "cumulative_weights_top_50_df = cumulative_weights_top_50_df.sort_values('Date')\n",
        "cumulative_weights_top_100_df = cumulative_weights_top_100_df.sort_values('Date')\n",
        "\n",
        "# Combine the DataFrames for Plotly\n",
        "cumulative_weights_top_10_df['Group'] = 'Top 10'\n",
        "cumulative_weights_top_20_df['Group'] = 'Top 20'\n",
        "cumulative_weights_top_50_df['Group'] = 'Top 50'\n",
        "cumulative_weights_top_100_df['Group'] = 'Top 100'\n",
        "plotly_df = pd.concat([cumulative_weights_top_10_df, cumulative_weights_top_20_df, cumulative_weights_top_50_df, cumulative_weights_top_100_df])\n",
        "\n",
        "# Create the Plotly line chart\n",
        "fig = px.line(plotly_df, x='Date', y='Cumulative Gewichtung (%)', color='Group', title=f\"Cumulative Gewichtung (%) Over Time for Top 10/20/50/100 Entries | {get_active_filters_headline()}\")\n",
        "\n",
        "# Save the Plotly chart as an HTML file\n",
        "filters_hash = hashlib.md5(get_active_filters_headline().encode()).hexdigest()\n",
        "output_file = os.path.join(output_dir, f'gewichtung_cumulative_top_10_20_50_100_{filters_hash}.html')\n",
        "fig.write_html(output_file)\n",
        "\n",
        "print(f\"Interactive Plotly chart saved to {output_file}\")"
      ],
      "id": "cc1cdb86e1293389",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-04-07T07:20:31.728058Z",
          "start_time": "2025-04-07T07:20:30.997128Z"
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import hashlib\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "\n",
        "# Create a dictionary to store the dates and corresponding aggregated \"Gewichtung (%)\" values for each Anlageklasse\n",
        "anlageklasse_entries = {}\n",
        "\n",
        "# Iterate over the DataFrames to aggregate the \"Gewichtung (%)\" values for each Anlageklasse\n",
        "for date, df in df_by_stichtag.items():\n",
        "    for anlageklasse in df['Anlageklasse'].unique():\n",
        "        if anlageklasse not in anlageklasse_entries:\n",
        "            anlageklasse_entries[anlageklasse] = {'dates': [], 'weights': []}\n",
        "\n",
        "        # Sum the \"Gewichtung (%)\" for the current Anlageklasse\n",
        "        total_weight = df[df['Anlageklasse'] == anlageklasse]['Gewichtung (%)'].sum()\n",
        "\n",
        "        anlageklasse_entries[anlageklasse]['dates'].append(date)\n",
        "        anlageklasse_entries[anlageklasse]['weights'].append(total_weight)\n",
        "\n",
        "# Plot the data using matplotlib\n",
        "plt.figure(figsize=(12, 8))\n",
        "for anlageklasse, data in anlageklasse_entries.items():\n",
        "    # Create a DataFrame for the current Anlageklasse\n",
        "    anlageklasse_df = pd.DataFrame({'Date': data['dates'], 'Gewichtung (%)': data['weights']})\n",
        "\n",
        "    # Convert the 'Date' column to datetime, invalid parsing will be set as NaT\n",
        "    anlageklasse_df['Date'] = pd.to_datetime(anlageklasse_df['Date'], errors='coerce')\n",
        "\n",
        "    # Drop rows with NaT values in the 'Date' column\n",
        "    anlageklasse_df = anlageklasse_df.dropna(subset=['Date'])\n",
        "\n",
        "    # Sort the DataFrame by date\n",
        "    anlageklasse_df = anlageklasse_df.sort_values('Date')\n",
        "\n",
        "    # Plot the data for the current Anlageklasse\n",
        "    plt.plot(anlageklasse_df['Date'], anlageklasse_df['Gewichtung (%)'], marker='o', markersize=marker_dot_size, label=anlageklasse)\n",
        "\n",
        "plt.title(f\"Total Gewichtung (%) Over Time by Anlageklasse | {get_active_filters_headline()}\")\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Total Gewichtung (%)')\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "plt.grid(True)\n",
        "# create a unique filename based on the filters\n",
        "filters_hash = hashlib.md5(get_active_filters_headline().encode()).hexdigest()\n",
        "plt.savefig(os.path.join(output_dir, f'gewichtung_by_anlageklasse_{filters_hash}.png'), dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "# Plot the data using plotly\n",
        "plotly_data = []\n",
        "for anlageklasse, data in anlageklasse_entries.items():\n",
        "    for date, weight in zip(data['dates'], data['weights']):\n",
        "        plotly_data.append({'Date': date, 'Gewichtung (%)': weight, 'Anlageklasse': anlageklasse})\n",
        "\n",
        "plotly_df = pd.DataFrame(plotly_data)\n",
        "\n",
        "# Convert the 'Date' column to datetime\n",
        "plotly_df['Date'] = pd.to_datetime(plotly_df['Date'], errors='coerce')\n",
        "\n",
        "# Drop rows with NaT values in the 'Date' column\n",
        "plotly_df = plotly_df.dropna(subset=['Date'])\n",
        "\n",
        "# Sort the DataFrame by date\n",
        "plotly_df = plotly_df.sort_values('Date')\n",
        "\n",
        "# Create the Plotly line chart\n",
        "fig = px.line(plotly_df, x='Date', y='Gewichtung (%)', color='Anlageklasse', title=f\"Total Gewichtung (%) Over Time by Anlageklasse | {get_active_filters_headline()}\", category_orders={'Anlageklasse': sorted(plotly_df['Anlageklasse'].unique())})\n",
        "\n",
        "# Save the Plotly chart as an HTML file\n",
        "output_file = os.path.join(output_dir, f'gewichtung_by_anlageklasse_{filters_hash}.html')\n",
        "fig.write_html(output_file)\n",
        "\n",
        "print(f\"Interactive Plotly chart saved to {output_file}\")"
      ],
      "id": "c3cfb34566220182",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-04-07T07:20:33.226963Z",
          "start_time": "2025-04-07T07:20:31.789233Z"
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import hashlib\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "\n",
        "# Create a dictionary to store the dates and corresponding aggregated \"Gewichtung (%)\" values for each sector\n",
        "sector_entries = {}\n",
        "\n",
        "# Iterate over the DataFrames to aggregate the \"Gewichtung (%)\" values for each sector\n",
        "for date, df in df_by_stichtag.items():\n",
        "    for sector in df['Sektor'].unique():\n",
        "        if sector not in sector_entries:\n",
        "            sector_entries[sector] = {'dates': [], 'weights': []}\n",
        "\n",
        "        # Sum the \"Gewichtung (%)\" for the current sector\n",
        "        total_weight = df[df['Sektor'] == sector]['Gewichtung (%)'].sum()\n",
        "\n",
        "        sector_entries[sector]['dates'].append(date)\n",
        "        sector_entries[sector]['weights'].append(total_weight)\n",
        "\n",
        "# Plot the data using matplotlib\n",
        "plt.figure(figsize=(12, 8))\n",
        "for sector, data in sector_entries.items():\n",
        "    # Create a DataFrame for the current sector\n",
        "    sector_df = pd.DataFrame({'Date': data['dates'], 'Gewichtung (%)': data['weights']})\n",
        "\n",
        "    # Convert the 'Date' column to datetime, invalid parsing will be set as NaT\n",
        "    sector_df['Date'] = pd.to_datetime(sector_df['Date'], errors='coerce')\n",
        "\n",
        "    # Drop rows with NaT values in the 'Date' column\n",
        "    sector_df = sector_df.dropna(subset=['Date'])\n",
        "\n",
        "    # Sort the DataFrame by date\n",
        "    sector_df = sector_df.sort_values('Date')\n",
        "\n",
        "    # Plot the data for the current sector\n",
        "    plt.plot(sector_df['Date'], sector_df['Gewichtung (%)'], marker='o', markersize=5, label=sector)\n",
        "\n",
        "plt.title(\"Total Gewichtung (%) Over Time by Sector\")\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Total Gewichtung (%)')\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "plt.grid(True)\n",
        "# create a unique filename based on the filters\n",
        "filters_hash = hashlib.md5(\"sector_analysis\".encode()).hexdigest()\n",
        "plt.savefig(os.path.join(output_dir, f'gewichtung_by_sector_{filters_hash}.png'), dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "# Plot the data using plotly\n",
        "plotly_data = []\n",
        "for sector, data in sector_entries.items():\n",
        "    for date, weight in zip(data['dates'], data['weights']):\n",
        "        plotly_data.append({'Date': date, 'Gewichtung (%)': weight, 'Sector': sector})\n",
        "\n",
        "plotly_df = pd.DataFrame(plotly_data)\n",
        "\n",
        "# Convert the 'Date' column to datetime\n",
        "plotly_df['Date'] = pd.to_datetime(plotly_df['Date'], errors='coerce')\n",
        "\n",
        "# Drop rows with NaT values in the 'Date' column\n",
        "plotly_df = plotly_df.dropna(subset=['Date'])\n",
        "\n",
        "# Sort the DataFrame by date\n",
        "plotly_df = plotly_df.sort_values('Date')\n",
        "\n",
        "# Create the Plotly line chart\n",
        "fig = px.line(plotly_df, x='Date', y='Gewichtung (%)', color='Sector', title=\"Total Gewichtung (%) Over Time by Sector\",\n",
        "              category_orders={'Sector': sorted(plotly_df['Sector'].unique())})\n",
        "\n",
        "# Save the Plotly chart as an HTML file\n",
        "output_file = os.path.join(output_dir, f'gewichtung_by_sector_{filters_hash}.html')\n",
        "fig.write_html(output_file)\n",
        "\n",
        "print(f\"Interactive Plotly chart saved to {output_file}\")"
      ],
      "id": "f2351ef627924e3",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-04-07T07:20:38.796509Z",
          "start_time": "2025-04-07T07:20:33.328130Z"
        }
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Identify the latest date in the dataset\n",
        "latest_stichtag = max(df_by_stichtag.keys(), key=lambda x: pd.to_datetime(x, format='%Y%m%d'))\n",
        "\n",
        "# Filter the data for the latest date\n",
        "latest_df = df_by_stichtag[latest_stichtag]\n",
        "\n",
        "# Group the data by country and get the top 10 entries by \"Gewichtung (%)\" for each country\n",
        "top_10_by_country = latest_df.groupby('Standort').apply(lambda x: x.nlargest(50, 'Gewichtung (%)')).reset_index(drop=True)\n",
        "\n",
        "# Plot the data\n",
        "plt.figure(figsize=(14, 10))\n",
        "for country in top_10_by_country['Standort'].unique():\n",
        "    country_df = top_10_by_country[top_10_by_country['Standort'] == country]\n",
        "    plt.barh(country_df['Name'], country_df['Gewichtung (%)'], label=country)\n",
        "\n",
        "plt.title(f'Top 50 \"Name\" by \"Gewichtung (%)\" for Each Country on {latest_stichtag}')\n",
        "plt.xlabel('Gewichtung (%)')\n",
        "plt.ylabel('Name')\n",
        "plt.legend(title='Country', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(output_dir, f'top_50_by_country_{latest_stichtag}.png'), dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ],
      "id": "cb96a3061affcee5",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-04-08T08:55:08.795409Z",
          "start_time": "2025-04-08T08:55:08.542106Z"
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import hashlib\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "\n",
        "# Identify the latest date in the dataset\n",
        "latest_stichtag = max(df_by_stichtag.keys(), key=lambda x: pd.to_datetime(x, format='%Y%m%d'))\n",
        "\n",
        "# Filter the data for the latest date\n",
        "latest_df = df_by_stichtag[latest_stichtag]\n",
        "\n",
        "# Group the data by country and get the top 10 entries by \"Gewichtung (%)\" for each country\n",
        "top_10_by_country = latest_df.groupby('Standort').apply(lambda x: x.nlargest(50, 'Gewichtung (%)')).reset_index(drop=True)\n",
        "\n",
        "# Create a DataFrame for Plotly\n",
        "plotly_data = []\n",
        "for country in top_10_by_country['Standort'].unique():\n",
        "    country_df = top_10_by_country[top_10_by_country['Standort'] == country]\n",
        "    for _, row in country_df.iterrows():\n",
        "        plotly_data.append({'Name': row['Name'], 'Gewichtung (%)': row['Gewichtung (%)'], 'Country': country})\n",
        "\n",
        "plotly_df = pd.DataFrame(plotly_data)\n",
        "\n",
        "# Create the Plotly bar chart\n",
        "fig = px.bar(plotly_df, x='Gewichtung (%)', y='Name', color='Country', orientation='h', title=f'Top 50 \"Name\" by \"Gewichtung (%)\" for Each Country on {latest_stichtag}')\n",
        "\n",
        "# Save the Plotly chart as an HTML file\n",
        "filters_hash = hashlib.md5(\"top_50_by_country\".encode()).hexdigest()\n",
        "output_file = os.path.join(output_dir, f'top_50_by_country_{latest_stichtag}_{filters_hash}.html')\n",
        "fig.write_html(output_file)\n",
        "\n",
        "print(f\"Interactive Plotly chart saved to {output_file}\")"
      ],
      "id": "4406f76109dfb3a",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-04-07T07:22:39.196225Z",
          "start_time": "2025-04-07T07:20:39.129006Z"
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import hashlib\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "\n",
        "# Create a dictionary to store the dates and corresponding \"Gewichtung (%)\" values for each Name\n",
        "name_entries = {}\n",
        "\n",
        "# Iterate over the DataFrames to extract the \"Gewichtung (%)\" values for each Name\n",
        "for date, df in df_by_stichtag.items():\n",
        "    for name in df['Name'].unique():\n",
        "        if name not in name_entries:\n",
        "            name_entries[name] = {'dates': [], 'weights': []}\n",
        "\n",
        "        # Get the \"Gewichtung (%)\" for the current Name\n",
        "        weight = df[df['Name'] == name]['Gewichtung (%)'].sum()\n",
        "\n",
        "        name_entries[name]['dates'].append(date)\n",
        "        name_entries[name]['weights'].append(weight)\n",
        "\n",
        "# Plot the data using matplotlib\n",
        "plt.figure(figsize=(12, 8))\n",
        "for name, data in name_entries.items():\n",
        "    # Create a DataFrame for the current Name\n",
        "    name_df = pd.DataFrame({'Date': data['dates'], 'Gewichtung (%)': data['weights']})\n",
        "\n",
        "    # Convert the 'Date' column to datetime, invalid parsing will be set as NaT\n",
        "    name_df['Date'] = pd.to_datetime(name_df['Date'], errors='coerce')\n",
        "\n",
        "    # Drop rows with NaT values in the 'Date' column\n",
        "    name_df = name_df.dropna(subset=['Date'])\n",
        "\n",
        "    # Sort the DataFrame by date\n",
        "    name_df = name_df.sort_values('Date')\n",
        "\n",
        "    # Plot the data for the current Name\n",
        "    plt.plot(name_df['Date'], name_df['Gewichtung (%)'], marker='o', markersize=2, label=name)\n",
        "\n",
        "plt.title(\"Gewichtung (%) Over Time for Each Name\")\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Gewichtung (%)')\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "plt.grid(True)\n",
        "# create a unique filename based on the filters\n",
        "filters_hash = hashlib.md5(\"name_analysis\".encode()).hexdigest()\n",
        "plt.savefig(os.path.join(output_dir, f'gewichtung_by_name_{filters_hash}.png'), dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "# Plot the data using plotly\n",
        "plotly_data = []\n",
        "for name, data in name_entries.items():\n",
        "    for date, weight in zip(data['dates'], data['weights']):\n",
        "        plotly_data.append({'Date': date, 'Gewichtung (%)': weight, 'Name': name})\n",
        "\n",
        "plotly_df = pd.DataFrame(plotly_data)\n",
        "\n",
        "# Convert the 'Date' column to datetime\n",
        "plotly_df['Date'] = pd.to_datetime(plotly_df['Date'], errors='coerce')\n",
        "\n",
        "# Drop rows with NaT values in the 'Date' column\n",
        "plotly_df = plotly_df.dropna(subset=['Date'])\n",
        "\n",
        "# Sort the DataFrame by date\n",
        "plotly_df = plotly_df.sort_values('Date')\n",
        "\n",
        "# Create the Plotly line chart\n",
        "fig = px.line(plotly_df, x='Date', y='Gewichtung (%)', color='Name', title=\"Gewichtung (%) Over Time for Each Name\",\n",
        "              category_orders={'Name': sorted(plotly_df['Name'].unique())})\n",
        "\n",
        "# Save the Plotly chart as an HTML file\n",
        "output_file = os.path.join(output_dir, f'gewichtung_by_name_LARGE_{filters_hash}.html')\n",
        "fig.write_html(output_file)\n",
        "\n",
        "print(f\"Interactive Plotly chart saved to {output_file}\")"
      ],
      "id": "fec96898d1d5a264",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "",
      "id": "9b224c2bd628bcdd"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat": 5,
  "nbformat_minor": 9
}
