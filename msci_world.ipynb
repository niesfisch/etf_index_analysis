{
  "cells": [
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-16T07:58:53.455809Z",
          "start_time": "2025-05-16T07:58:53.450938Z"
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "import hashlib\n",
        "import os\n",
        "import warnings\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "import pytz\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# ------------------ CONFIGURATION ------------------\n",
        "json_data_dir = './download/data'\n",
        "output_dir = './out/'\n",
        "\n",
        "marker_dot_size = 0\n",
        "\n",
        "## -------- some filters to remove entries from the data --------\n",
        "# e.g. 'APPLE INC', 'Name ABC'\n",
        "remove_by_name = []\n",
        "# e.g. 'AAPL', 'MSFT'\n",
        "remove_by_ticker = []\n",
        "# e.g. 'Versorger', 'Immobilien', 'Energie', 'Materialien', 'Telekommunikationsdienste'\n",
        "remove_by_sector = []\n",
        "# 'Vereinigte Staaten', 'Deutschland', 'Frankreich'\n",
        "remove_by_standort = []\n",
        "# ---------------------------------------------------\n",
        "\n",
        "# -- some checks\n",
        "if not os.path.exists(json_data_dir):\n",
        "    raise FileNotFoundError(f\"File not found: {json_data_dir}\")\n",
        "\n",
        "# create output directory if not exists\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "print(f\"Output directory: {output_dir}\")\n"
      ],
      "id": "5f9fb6365fbe6827",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-16T07:58:54.866951Z",
          "start_time": "2025-05-16T07:58:53.528787Z"
        }
      },
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# create a hashmap for each day containing the df\n",
        "df_by_stichtag = {}\n",
        "\n",
        "# iterate over all files in the data directory\n",
        "for json_file in os.listdir(json_data_dir):\n",
        "    if not json_file.endswith('.json'):\n",
        "        continue\n",
        "\n",
        "    # Load JSON data\n",
        "    with open(os.path.join(json_data_dir, json_file), 'r', encoding='utf-8') as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    # Extract the aaData array\n",
        "    aaData = data['aaData']\n",
        "\n",
        "    # Define the column names\n",
        "    columns = [\n",
        "        'Emittententicker', 'Name', 'Sektor', 'Anlageklasse', 'Marktwert',\n",
        "        'Gewichtung (%)', 'Nominalwert', 'Nominale', 'Kurs', 'Standort',\n",
        "        'Börse', 'Marktwährung'\n",
        "    ]\n",
        "    # Create a list of rows\n",
        "    rows = []\n",
        "    for item in aaData:\n",
        "        row = [\n",
        "            item[0],  # Emittententicker\n",
        "            item[1],  # Name\n",
        "            item[2],  # Sektor\n",
        "            item[3],  # Anlageklasse\n",
        "            item[4]['raw'],  # Marktwert\n",
        "            item[5]['raw'],  # Gewichtung (%)\n",
        "            item[6]['raw'],  # Nominalwert\n",
        "            item[7]['raw'],  # Nominale\n",
        "            item[9]['raw'],  # Kurs\n",
        "            item[10],  # Standort\n",
        "            item[11],  # Börse\n",
        "            item[12]  # Marktwährung\n",
        "        ]\n",
        "        rows.append(row)\n",
        "\n",
        "    # Create DataFrame\n",
        "    df = pd.DataFrame(rows, columns=columns)\n",
        "\n",
        "    stichtag = json_file.split('.')[0]\n",
        "\n",
        "    df_by_stichtag[stichtag] = df\n",
        "\n",
        "print(f\"Loaded {len(df_by_stichtag)} dataframes\")\n",
        "\n",
        "# # find the latest entry in the df_by_stichtag by converting the keys to datetime\n",
        "latest_stichtag = max(df_by_stichtag.keys(), key=lambda x: pd.to_datetime(x, format='%Y%m%d'))\n",
        "print(f\"Latest stichtag: {latest_stichtag}\")\n",
        "\n",
        "#df_by_stichtag"
      ],
      "id": "9ef0cfb17f647c0b",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-16T07:58:54.920027Z",
          "start_time": "2025-05-16T07:58:54.915315Z"
        }
      },
      "cell_type": "code",
      "source": [
        "def get_active_filters_headline():\n",
        "    filters = []\n",
        "    if remove_by_name:\n",
        "        filters.append(f\"Name: {', '.join(remove_by_name)}\")\n",
        "    if remove_by_ticker:\n",
        "        filters.append(f\"Ticker: {', '.join(remove_by_ticker)}\")\n",
        "    if remove_by_sector:\n",
        "        filters.append(f\"Sektor: {', '.join(remove_by_sector)}\")\n",
        "    if remove_by_standort:\n",
        "        filters.append(f\"Standort: {', '.join(remove_by_standort)}\")\n",
        "\n",
        "    return 'filtered: [' +  ' | '.join(filters) + ']' if filters else 'no filters applied'\n",
        "\n",
        "# remove entries by \"remove_\" lists\n",
        "for stichtag, df in df_by_stichtag.items():\n",
        "    # Remove entries by name\n",
        "    for name in remove_by_name:\n",
        "        df = df[~df['Name'].str.contains(name, na=False)]\n",
        "\n",
        "    # Remove entries by ticker\n",
        "    for ticker in remove_by_ticker:\n",
        "        df = df[~df['Emittententicker'].str.contains(ticker, na=False)]\n",
        "\n",
        "    # Remove entries by sector\n",
        "    for sector in remove_by_sector:\n",
        "        df = df[~df['Sektor'].str.contains(sector, na=False)]\n",
        "\n",
        "    # Remove entries by standort\n",
        "    for standort in remove_by_standort:\n",
        "        df = df[~df['Standort'].str.contains(standort, na=False)]\n",
        "\n",
        "    # Update the DataFrame in the dictionary\n",
        "    df_by_stichtag[stichtag] = df\n",
        "\n",
        "print(f\"Active filters: {get_active_filters_headline()}\")"
      ],
      "id": "efdc7d0dde212aca",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-16T07:58:56.812689Z",
          "start_time": "2025-05-16T07:58:55.006623Z"
        }
      },
      "cell_type": "code",
      "source": [
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "line_styles = ['-', '--', '-.', ':', ' ', '', 'solid', 'dashed', 'dashdot', 'dotted']\n",
        "line_style_cycle = iter(line_styles)\n",
        "\n",
        "# Create a dictionary to store the dates and corresponding aggregated \"Gewichtung (%)\" values for each Standort\n",
        "standort_entries = {}\n",
        "\n",
        "# Iterate over the DataFrames to aggregate the \"Gewichtung (%)\" values for each Standort\n",
        "for date, df in df_by_stichtag.items():\n",
        "    for standort in df['Standort'].unique():\n",
        "        if standort not in standort_entries:\n",
        "            standort_entries[standort] = {'dates': [], 'weights': []}\n",
        "\n",
        "        # Sum the \"Gewichtung (%)\" for the current Standort\n",
        "        total_weight = df[df['Standort'] == standort]['Gewichtung (%)'].sum()\n",
        "\n",
        "        standort_entries[standort]['dates'].append(date)\n",
        "        standort_entries[standort]['weights'].append(total_weight)\n",
        "\n",
        "# Plot the data\n",
        "plt.figure(figsize=(12, 8))\n",
        "for standort, data in standort_entries.items():\n",
        "    # Create a DataFrame for the current Standort\n",
        "    standort_df = pd.DataFrame({'Date': data['dates'], 'Gewichtung (%)': data['weights']})\n",
        "\n",
        "    # Convert the 'Date' column to datetime, invalid parsing will be set as NaT\n",
        "    standort_df['Date'] = pd.to_datetime(standort_df['Date'], errors='coerce')\n",
        "\n",
        "    # Drop rows with NaT values in the 'Date' column\n",
        "    standort_df = standort_df.dropna(subset=['Date'])\n",
        "\n",
        "    # Sort the DataFrame by date\n",
        "    standort_df = standort_df.sort_values('Date')\n",
        "\n",
        "    # get random line style\n",
        "    random_line_style = random.choice(line_styles)\n",
        "\n",
        "    # Plot the data for the current Standort\n",
        "    plt.plot(standort_df['Date'], standort_df['Gewichtung (%)'], marker='o', markersize=marker_dot_size, label=standort, linestyle=random_line_style)\n",
        "\n",
        "plt.title(f\"Total Gewichtung (%) Over Time by Standort | {get_active_filters_headline()}\")\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Total Gewichtung (%)')\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "plt.grid(True)\n",
        "# if filters\n",
        "# create a unique filename based on the filters\n",
        "filters_hash = hashlib.md5(get_active_filters_headline().encode()).hexdigest()\n",
        "plt.savefig(os.path.join(output_dir, f'gewichtung_by_standort_{filters_hash}.png'), dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ],
      "id": "67d6865ec7f92c7b",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-16T07:58:57.929208Z",
          "start_time": "2025-05-16T07:58:56.866293Z"
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import hashlib\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "\n",
        "# Create a dictionary to store the dates and corresponding aggregated \"Gewichtung (%)\" values for each Standort\n",
        "standort_entries = {}\n",
        "\n",
        "# Iterate over the DataFrames to aggregate the \"Gewichtung (%)\" values for each Standort\n",
        "for date, df in df_by_stichtag.items():\n",
        "    for standort in df['Standort'].unique():\n",
        "        if standort not in standort_entries:\n",
        "            standort_entries[standort] = {'dates': [], 'weights': []}\n",
        "\n",
        "        # Sum the \"Gewichtung (%)\" for the current Standort\n",
        "        total_weight = df[df['Standort'] == standort]['Gewichtung (%)'].sum()\n",
        "\n",
        "        standort_entries[standort]['dates'].append(date)\n",
        "        standort_entries[standort]['weights'].append(total_weight)\n",
        "\n",
        "# Create a DataFrame for Plotly\n",
        "plotly_data = []\n",
        "for standort, data in standort_entries.items():\n",
        "    for date, weight in zip(data['dates'], data['weights']):\n",
        "        plotly_data.append({'Date': date, 'Gewichtung (%)': weight, 'Standort': standort})\n",
        "\n",
        "plotly_df = pd.DataFrame(plotly_data)\n",
        "\n",
        "# Convert the 'Date' column to datetime\n",
        "plotly_df['Date'] = pd.to_datetime(plotly_df['Date'], errors='coerce')\n",
        "\n",
        "# Drop rows with NaT values in the 'Date' column\n",
        "plotly_df = plotly_df.dropna(subset=['Date'])\n",
        "\n",
        "# Sort the DataFrame by date\n",
        "plotly_df = plotly_df.sort_values('Date')\n",
        "\n",
        "# Create the Plotly line chart\n",
        "fig = px.line(plotly_df, x='Date', y='Gewichtung (%)', color='Standort', title=f\"Total Gewichtung (%) Over Time by Standort | {get_active_filters_headline()}\", category_orders={'Standort': sorted(plotly_df['Standort'].unique())})\n",
        "\n",
        "# Save the Plotly chart as an HTML file\n",
        "filters_hash = hashlib.md5(get_active_filters_headline().encode()).hexdigest()\n",
        "output_file = os.path.join(output_dir, f'gewichtung_by_standort_{filters_hash}.html')\n",
        "fig.write_html(output_file)\n",
        "\n",
        "print(f\"Interactive Plotly chart saved to {output_file}\")"
      ],
      "id": "1775cd034f53f103",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-16T07:58:58.933372Z",
          "start_time": "2025-05-16T07:58:58.075090Z"
        }
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Identify the top 10 entries by \"Gewichtung (%)\" in the 20250131 DataFrame\n",
        "top_10_df = df_by_stichtag[latest_stichtag].nlargest(10, 'Gewichtung (%)')\n",
        "\n",
        "# Create a dictionary to store the dates and corresponding \"Gewichtung (%)\" values for each top entry\n",
        "top_entries = {ticker: {'dates': [], 'weights': []} for ticker in top_10_df['Name']}\n",
        "\n",
        "# Iterate over the DataFrames to extract the \"Gewichtung (%)\" values for the top 10 entries\n",
        "for date, df in df_by_stichtag.items():\n",
        "    for ticker in top_entries.keys():\n",
        "        row = df[df['Name'] == ticker]\n",
        "        if not row.empty:\n",
        "            top_entries[ticker]['dates'].append(date)\n",
        "            top_entries[ticker]['weights'].append(row['Gewichtung (%)'].values[0])\n",
        "\n",
        "# Plot the data\n",
        "plt.figure(figsize=(12, 8))\n",
        "for ticker, data in top_entries.items():\n",
        "    # Create a DataFrame for the current ticker\n",
        "    ticker_df = pd.DataFrame({'Date': data['dates'], 'Gewichtung (%)': data['weights']})\n",
        "\n",
        "    # Convert the 'Date' column to datetime, invalid parsing will be set as NaT\n",
        "    ticker_df['Date'] = pd.to_datetime(ticker_df['Date'], errors='coerce')\n",
        "\n",
        "    # Drop rows with NaT values in the 'Date' column\n",
        "    ticker_df = ticker_df.dropna(subset=['Date'])\n",
        "\n",
        "    # Sort the DataFrame by date\n",
        "    ticker_df = ticker_df.sort_values('Date')\n",
        "\n",
        "    # Plot the data for the current ticker\n",
        "    plt.plot(ticker_df['Date'], ticker_df['Gewichtung (%)'], marker='o', markersize=marker_dot_size, label=ticker)\n",
        "\n",
        "plt.title(f\"Gewichtung (%) Over Time for Top 10 Entries on {latest_stichtag} | {get_active_filters_headline()}\")\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Gewichtung (%)')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "# create a unique filename based on the filters\n",
        "filters_hash = hashlib.md5(get_active_filters_headline().encode()).hexdigest()\n",
        "plt.savefig(os.path.join(output_dir, f'gewichtung_top_10_{latest_stichtag}_{filters_hash}.png'), dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ],
      "id": "2beddf9eba45e1dc",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-16T07:58:59.446936Z",
          "start_time": "2025-05-16T07:58:59.091122Z"
        }
      },
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "\n",
        "# Identify the top 10 entries by \"Gewichtung (%)\" in the latest DataFrame\n",
        "top_10_df = df_by_stichtag[latest_stichtag].nlargest(10, 'Gewichtung (%)')\n",
        "\n",
        "# Create a dictionary to store the dates and corresponding \"Gewichtung (%)\" values for each top entry\n",
        "top_entries = {ticker: {'dates': [], 'weights': []} for ticker in top_10_df['Name']}\n",
        "\n",
        "# Iterate over the DataFrames to extract the \"Gewichtung (%)\" values for the top 10 entries\n",
        "for date, df in df_by_stichtag.items():\n",
        "    for ticker in top_entries.keys():\n",
        "        row = df[df['Name'] == ticker]\n",
        "        if not row.empty:\n",
        "            top_entries[ticker]['dates'].append(date)\n",
        "            top_entries[ticker]['weights'].append(row['Gewichtung (%)'].values[0])\n",
        "\n",
        "# Create a DataFrame for Plotly\n",
        "plotly_data = []\n",
        "for ticker, data in top_entries.items():\n",
        "    for date, weight in zip(data['dates'], data['weights']):\n",
        "        plotly_data.append({'Date': date, 'Gewichtung (%)': weight, 'Ticker': ticker})\n",
        "\n",
        "plotly_df = pd.DataFrame(plotly_data)\n",
        "\n",
        "# Convert the 'Date' column to datetime\n",
        "plotly_df['Date'] = pd.to_datetime(plotly_df['Date'], errors='coerce')\n",
        "\n",
        "# Drop rows with NaT values in the 'Date' column\n",
        "plotly_df = plotly_df.dropna(subset=['Date'])\n",
        "\n",
        "# Sort the DataFrame by date\n",
        "plotly_df = plotly_df.sort_values('Date')\n",
        "\n",
        "# Create the Plotly line chart\n",
        "fig = px.line(plotly_df, x='Date', y='Gewichtung (%)', color='Ticker', title=f\"Gewichtung (%) Over Time for Top 10 Entries on {latest_stichtag} | {get_active_filters_headline()}\", category_orders={'Ticker': sorted(plotly_df['Ticker'].unique())})\n",
        "\n",
        "# Save the Plotly chart as an HTML file\n",
        "filters_hash = hashlib.md5(get_active_filters_headline().encode()).hexdigest()\n",
        "output_file = os.path.join(output_dir, f'gewichtung_top_10_{latest_stichtag}_{filters_hash}.html')\n",
        "fig.write_html(output_file)\n",
        "\n",
        "print(f\"Interactive Plotly chart saved to {output_file}\")"
      ],
      "id": "8dbdda6f75b9e287",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-16T07:58:59.848986Z",
          "start_time": "2025-05-16T07:58:59.517627Z"
        }
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Extract the corresponding DataFrame\n",
        "most_recent_df = df_by_stichtag[latest_stichtag]\n",
        "\n",
        "# Create a scatter plot of the \"Gewichtung (%)\" values\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.scatter(most_recent_df['Name'], most_recent_df['Gewichtung (%)'], alpha=0.6, s=20)\n",
        "plt.title(f'Gewichtung (%) for the Most Recent Stichtag: {latest_stichtag} | {get_active_filters_headline()}')\n",
        "plt.xlabel('')\n",
        "plt.xticks([])\n",
        "plt.ylabel('Gewichtung (%)')\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "# create a unique filename based on the filters\n",
        "filters_hash = hashlib.md5(get_active_filters_headline().encode()).hexdigest()\n",
        "plt.savefig(os.path.join(output_dir, f'gewichtung_scatter_{latest_stichtag}_{filters_hash}.png'), dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ],
      "id": "f71bbd45dee8fe60",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-16T07:58:59.960299Z",
          "start_time": "2025-05-16T07:58:59.921680Z"
        }
      },
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "\n",
        "# Extract the corresponding DataFrame\n",
        "most_recent_df = df_by_stichtag[latest_stichtag]\n",
        "\n",
        "# Create a Plotly scatter plot of the \"Gewichtung (%)\" values\n",
        "fig = px.scatter(most_recent_df, x='Name', y='Gewichtung (%)', title=f'Gewichtung (%) for the Most Recent Stichtag: {latest_stichtag} | {get_active_filters_headline()}')\n",
        "\n",
        "# Save the Plotly chart as an HTML file\n",
        "filters_hash = hashlib.md5(get_active_filters_headline().encode()).hexdigest()\n",
        "output_file = os.path.join(output_dir, f'gewichtung_scatter_{latest_stichtag}_{filters_hash}.html')\n",
        "fig.write_html(output_file)\n",
        "\n",
        "print(f\"Interactive Plotly chart saved to {output_file}\")"
      ],
      "id": "ba3c86919e32216d",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-16T07:59:00.824354Z",
          "start_time": "2025-05-16T07:59:00.045287Z"
        }
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Create dictionaries to store the cumulative \"Gewichtung (%)\" values for each date\n",
        "cumulative_weights_top_10 = {}\n",
        "cumulative_weights_top_20 = {}\n",
        "cumulative_weights_top_50 = {}\n",
        "cumulative_weights_top_100 = {}\n",
        "\n",
        "# Iterate over the DataFrames to calculate the cumulative \"Gewichtung (%)\" for the top 20, top 50, and top 100 entries\n",
        "for date, df in df_by_stichtag.items():\n",
        "    # Identify the top 20, top 50, and top 100 entries by \"Gewichtung (%)\"\n",
        "    top_10_df = df.nlargest(10, 'Gewichtung (%)')\n",
        "    top_20_df = df.nlargest(20, 'Gewichtung (%)')\n",
        "    top_50_df = df.nlargest(50, 'Gewichtung (%)')\n",
        "    top_100_df = df.nlargest(100, 'Gewichtung (%)')\n",
        "\n",
        "    # Calculate the cumulative \"Gewichtung (%)\" for the top 20, top 50, and top 100 entries\n",
        "    cumulative_weight_top_10 = top_10_df['Gewichtung (%)'].sum()\n",
        "    cumulative_weight_top_20 = top_20_df['Gewichtung (%)'].sum()\n",
        "    cumulative_weight_top_50 = top_50_df['Gewichtung (%)'].sum()\n",
        "    cumulative_weight_top_100 = top_100_df['Gewichtung (%)'].sum()\n",
        "\n",
        "    # Store the cumulative weights for the current date\n",
        "    cumulative_weights_top_10[date] = cumulative_weight_top_10\n",
        "    cumulative_weights_top_20[date] = cumulative_weight_top_20\n",
        "    cumulative_weights_top_50[date] = cumulative_weight_top_50\n",
        "    cumulative_weights_top_100[date] = cumulative_weight_top_100\n",
        "\n",
        "# Convert the cumulative weights dictionaries to DataFrames\n",
        "cumulative_weights_top_10_df = pd.DataFrame(list(cumulative_weights_top_10.items()),\n",
        "                                            columns=['Date', 'Cumulative Gewichtung (%)'])\n",
        "cumulative_weights_top_20_df = pd.DataFrame(list(cumulative_weights_top_20.items()),\n",
        "                                            columns=['Date', 'Cumulative Gewichtung (%)'])\n",
        "cumulative_weights_top_50_df = pd.DataFrame(list(cumulative_weights_top_50.items()),\n",
        "                                            columns=['Date', 'Cumulative Gewichtung (%)'])\n",
        "cumulative_weights_top_100_df = pd.DataFrame(list(cumulative_weights_top_100.items()),\n",
        "                                             columns=['Date', 'Cumulative Gewichtung (%)'])\n",
        "\n",
        "# Convert the 'Date' columns to datetime, invalid parsing will be set as NaT\n",
        "cumulative_weights_top_10_df['Date'] = pd.to_datetime(cumulative_weights_top_10_df['Date'], errors='coerce')\n",
        "cumulative_weights_top_20_df['Date'] = pd.to_datetime(cumulative_weights_top_20_df['Date'], errors='coerce')\n",
        "cumulative_weights_top_50_df['Date'] = pd.to_datetime(cumulative_weights_top_50_df['Date'], errors='coerce')\n",
        "cumulative_weights_top_100_df['Date'] = pd.to_datetime(cumulative_weights_top_100_df['Date'], errors='coerce')\n",
        "\n",
        "# Drop rows with NaT values in the 'Date' columns\n",
        "cumulative_weights_top_10_df = cumulative_weights_top_10_df.dropna(subset=['Date'])\n",
        "cumulative_weights_top_20_df = cumulative_weights_top_20_df.dropna(subset=['Date'])\n",
        "cumulative_weights_top_50_df = cumulative_weights_top_50_df.dropna(subset=['Date'])\n",
        "cumulative_weights_top_100_df = cumulative_weights_top_100_df.dropna(subset=['Date'])\n",
        "\n",
        "# Sort the DataFrames by date\n",
        "cumulative_weights_top_10_df = cumulative_weights_top_10_df.sort_values('Date')\n",
        "cumulative_weights_top_20_df = cumulative_weights_top_20_df.sort_values('Date')\n",
        "cumulative_weights_top_50_df = cumulative_weights_top_50_df.sort_values('Date')\n",
        "cumulative_weights_top_100_df = cumulative_weights_top_100_df.sort_values('Date')\n",
        "\n",
        "# Plot the cumulative \"Gewichtung (%)\" over time for top 20, top 50, and top 100 entries\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.plot(cumulative_weights_top_10_df['Date'], cumulative_weights_top_10_df['Cumulative Gewichtung (%)'], marker='o',\n",
        "         markersize=marker_dot_size, label='Top 10')\n",
        "plt.plot(cumulative_weights_top_20_df['Date'], cumulative_weights_top_20_df['Cumulative Gewichtung (%)'], marker='o',\n",
        "         markersize=marker_dot_size, label='Top 20')\n",
        "plt.plot(cumulative_weights_top_50_df['Date'], cumulative_weights_top_50_df['Cumulative Gewichtung (%)'], marker='o',\n",
        "         markersize=marker_dot_size, label='Top 50')\n",
        "plt.plot(cumulative_weights_top_100_df['Date'], cumulative_weights_top_100_df['Cumulative Gewichtung (%)'],\n",
        "         markersize=marker_dot_size, marker='o', label='Top 100')\n",
        "\n",
        "plt.title(f\"Cumulative Gewichtung (%) Over Time for Top 10/20/50/100 Entries | {get_active_filters_headline()}\")\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Cumulative Gewichtung (%)')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "# create a unique filename based on the filters\n",
        "filters_hash = hashlib.md5(get_active_filters_headline().encode()).hexdigest()\n",
        "plt.savefig(os.path.join(output_dir, f'gewichtung_cumulative_top_10_20_50_100_{filters_hash}.png'), dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ],
      "id": "eb0b9e3f8cd64165",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-16T07:59:01.291601Z",
          "start_time": "2025-05-16T07:59:00.882480Z"
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import hashlib\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "\n",
        "# Create dictionaries to store the cumulative \"Gewichtung (%)\" values for each date\n",
        "cumulative_weights_top_10 = {}\n",
        "cumulative_weights_top_20 = {}\n",
        "cumulative_weights_top_50 = {}\n",
        "cumulative_weights_top_100 = {}\n",
        "\n",
        "# Iterate over the DataFrames to calculate the cumulative \"Gewichtung (%)\" for the top 10, top 20, top 50, and top 100 entries\n",
        "for date, df in df_by_stichtag.items():\n",
        "    # Identify the top 10, top 20, top 50, and top 100 entries by \"Gewichtung (%)\"\n",
        "    top_10_df = df.nlargest(10, 'Gewichtung (%)')\n",
        "    top_20_df = df.nlargest(20, 'Gewichtung (%)')\n",
        "    top_50_df = df.nlargest(50, 'Gewichtung (%)')\n",
        "    top_100_df = df.nlargest(100, 'Gewichtung (%)')\n",
        "\n",
        "    # Calculate the cumulative \"Gewichtung (%)\" for the top 10, top 20, top 50, and top 100 entries\n",
        "    cumulative_weight_top_10 = top_10_df['Gewichtung (%)'].sum()\n",
        "    cumulative_weight_top_20 = top_20_df['Gewichtung (%)'].sum()\n",
        "    cumulative_weight_top_50 = top_50_df['Gewichtung (%)'].sum()\n",
        "    cumulative_weight_top_100 = top_100_df['Gewichtung (%)'].sum()\n",
        "\n",
        "    # Store the cumulative weights for the current date\n",
        "    cumulative_weights_top_10[date] = cumulative_weight_top_10\n",
        "    cumulative_weights_top_20[date] = cumulative_weight_top_20\n",
        "    cumulative_weights_top_50[date] = cumulative_weight_top_50\n",
        "    cumulative_weights_top_100[date] = cumulative_weight_top_100\n",
        "\n",
        "# Convert the cumulative weights dictionaries to DataFrames\n",
        "cumulative_weights_top_10_df = pd.DataFrame(list(cumulative_weights_top_10.items()), columns=['Date', 'Cumulative Gewichtung (%)'])\n",
        "cumulative_weights_top_20_df = pd.DataFrame(list(cumulative_weights_top_20.items()), columns=['Date', 'Cumulative Gewichtung (%)'])\n",
        "cumulative_weights_top_50_df = pd.DataFrame(list(cumulative_weights_top_50.items()), columns=['Date', 'Cumulative Gewichtung (%)'])\n",
        "cumulative_weights_top_100_df = pd.DataFrame(list(cumulative_weights_top_100.items()), columns=['Date', 'Cumulative Gewichtung (%)'])\n",
        "\n",
        "# Convert the 'Date' columns to datetime\n",
        "cumulative_weights_top_10_df['Date'] = pd.to_datetime(cumulative_weights_top_10_df['Date'], errors='coerce')\n",
        "cumulative_weights_top_20_df['Date'] = pd.to_datetime(cumulative_weights_top_20_df['Date'], errors='coerce')\n",
        "cumulative_weights_top_50_df['Date'] = pd.to_datetime(cumulative_weights_top_50_df['Date'], errors='coerce')\n",
        "cumulative_weights_top_100_df['Date'] = pd.to_datetime(cumulative_weights_top_100_df['Date'], errors='coerce')\n",
        "\n",
        "# Drop rows with NaT values in the 'Date' columns\n",
        "cumulative_weights_top_10_df = cumulative_weights_top_10_df.dropna(subset=['Date'])\n",
        "cumulative_weights_top_20_df = cumulative_weights_top_20_df.dropna(subset=['Date'])\n",
        "cumulative_weights_top_50_df = cumulative_weights_top_50_df.dropna(subset=['Date'])\n",
        "cumulative_weights_top_100_df = cumulative_weights_top_100_df.dropna(subset=['Date'])\n",
        "\n",
        "# Sort the DataFrames by date\n",
        "cumulative_weights_top_10_df = cumulative_weights_top_10_df.sort_values('Date')\n",
        "cumulative_weights_top_20_df = cumulative_weights_top_20_df.sort_values('Date')\n",
        "cumulative_weights_top_50_df = cumulative_weights_top_50_df.sort_values('Date')\n",
        "cumulative_weights_top_100_df = cumulative_weights_top_100_df.sort_values('Date')\n",
        "\n",
        "# Combine the DataFrames for Plotly\n",
        "cumulative_weights_top_10_df['Group'] = 'Top 10'\n",
        "cumulative_weights_top_20_df['Group'] = 'Top 20'\n",
        "cumulative_weights_top_50_df['Group'] = 'Top 50'\n",
        "cumulative_weights_top_100_df['Group'] = 'Top 100'\n",
        "plotly_df = pd.concat([cumulative_weights_top_10_df, cumulative_weights_top_20_df, cumulative_weights_top_50_df, cumulative_weights_top_100_df])\n",
        "\n",
        "# Create the Plotly line chart\n",
        "fig = px.line(plotly_df, x='Date', y='Cumulative Gewichtung (%)', color='Group', title=f\"Cumulative Gewichtung (%) Over Time for Top 10/20/50/100 Entries | {get_active_filters_headline()}\")\n",
        "\n",
        "# Save the Plotly chart as an HTML file\n",
        "filters_hash = hashlib.md5(get_active_filters_headline().encode()).hexdigest()\n",
        "output_file = os.path.join(output_dir, f'gewichtung_cumulative_top_10_20_50_100_{filters_hash}.html')\n",
        "fig.write_html(output_file)\n",
        "\n",
        "print(f\"Interactive Plotly chart saved to {output_file}\")"
      ],
      "id": "cc1cdb86e1293389",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-16T07:59:02.033113Z",
          "start_time": "2025-05-16T07:59:01.359798Z"
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import hashlib\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "\n",
        "# Create a dictionary to store the dates and corresponding aggregated \"Gewichtung (%)\" values for each Anlageklasse\n",
        "anlageklasse_entries = {}\n",
        "\n",
        "# Iterate over the DataFrames to aggregate the \"Gewichtung (%)\" values for each Anlageklasse\n",
        "for date, df in df_by_stichtag.items():\n",
        "    for anlageklasse in df['Anlageklasse'].unique():\n",
        "        if anlageklasse not in anlageklasse_entries:\n",
        "            anlageklasse_entries[anlageklasse] = {'dates': [], 'weights': []}\n",
        "\n",
        "        # Sum the \"Gewichtung (%)\" for the current Anlageklasse\n",
        "        total_weight = df[df['Anlageklasse'] == anlageklasse]['Gewichtung (%)'].sum()\n",
        "\n",
        "        anlageklasse_entries[anlageklasse]['dates'].append(date)\n",
        "        anlageklasse_entries[anlageklasse]['weights'].append(total_weight)\n",
        "\n",
        "# Plot the data using matplotlib\n",
        "plt.figure(figsize=(12, 8))\n",
        "for anlageklasse, data in anlageklasse_entries.items():\n",
        "    # Create a DataFrame for the current Anlageklasse\n",
        "    anlageklasse_df = pd.DataFrame({'Date': data['dates'], 'Gewichtung (%)': data['weights']})\n",
        "\n",
        "    # Convert the 'Date' column to datetime, invalid parsing will be set as NaT\n",
        "    anlageklasse_df['Date'] = pd.to_datetime(anlageklasse_df['Date'], errors='coerce')\n",
        "\n",
        "    # Drop rows with NaT values in the 'Date' column\n",
        "    anlageklasse_df = anlageklasse_df.dropna(subset=['Date'])\n",
        "\n",
        "    # Sort the DataFrame by date\n",
        "    anlageklasse_df = anlageklasse_df.sort_values('Date')\n",
        "\n",
        "    # Plot the data for the current Anlageklasse\n",
        "    plt.plot(anlageklasse_df['Date'], anlageklasse_df['Gewichtung (%)'], marker='o', markersize=marker_dot_size, label=anlageklasse)\n",
        "\n",
        "plt.title(f\"Total Gewichtung (%) Over Time by Anlageklasse | {get_active_filters_headline()}\")\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Total Gewichtung (%)')\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "plt.grid(True)\n",
        "# create a unique filename based on the filters\n",
        "filters_hash = hashlib.md5(get_active_filters_headline().encode()).hexdigest()\n",
        "plt.savefig(os.path.join(output_dir, f'gewichtung_by_anlageklasse_{filters_hash}.png'), dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "# Plot the data using plotly\n",
        "plotly_data = []\n",
        "for anlageklasse, data in anlageklasse_entries.items():\n",
        "    for date, weight in zip(data['dates'], data['weights']):\n",
        "        plotly_data.append({'Date': date, 'Gewichtung (%)': weight, 'Anlageklasse': anlageklasse})\n",
        "\n",
        "plotly_df = pd.DataFrame(plotly_data)\n",
        "\n",
        "# Convert the 'Date' column to datetime\n",
        "plotly_df['Date'] = pd.to_datetime(plotly_df['Date'], errors='coerce')\n",
        "\n",
        "# Drop rows with NaT values in the 'Date' column\n",
        "plotly_df = plotly_df.dropna(subset=['Date'])\n",
        "\n",
        "# Sort the DataFrame by date\n",
        "plotly_df = plotly_df.sort_values('Date')\n",
        "\n",
        "# Create the Plotly line chart\n",
        "fig = px.line(plotly_df, x='Date', y='Gewichtung (%)', color='Anlageklasse', title=f\"Total Gewichtung (%) Over Time by Anlageklasse | {get_active_filters_headline()}\", category_orders={'Anlageklasse': sorted(plotly_df['Anlageklasse'].unique())})\n",
        "\n",
        "# Save the Plotly chart as an HTML file\n",
        "output_file = os.path.join(output_dir, f'gewichtung_by_anlageklasse_{filters_hash}.html')\n",
        "fig.write_html(output_file)\n",
        "\n",
        "print(f\"Interactive Plotly chart saved to {output_file}\")"
      ],
      "id": "c3cfb34566220182",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-16T07:59:03.434620Z",
          "start_time": "2025-05-16T07:59:02.102337Z"
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import hashlib\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "\n",
        "# Create a dictionary to store the dates and corresponding aggregated \"Gewichtung (%)\" values for each sector\n",
        "sector_entries = {}\n",
        "\n",
        "# Iterate over the DataFrames to aggregate the \"Gewichtung (%)\" values for each sector\n",
        "for date, df in df_by_stichtag.items():\n",
        "    for sector in df['Sektor'].unique():\n",
        "        if sector not in sector_entries:\n",
        "            sector_entries[sector] = {'dates': [], 'weights': []}\n",
        "\n",
        "        # Sum the \"Gewichtung (%)\" for the current sector\n",
        "        total_weight = df[df['Sektor'] == sector]['Gewichtung (%)'].sum()\n",
        "\n",
        "        sector_entries[sector]['dates'].append(date)\n",
        "        sector_entries[sector]['weights'].append(total_weight)\n",
        "\n",
        "# Plot the data using matplotlib\n",
        "plt.figure(figsize=(12, 8))\n",
        "for sector, data in sector_entries.items():\n",
        "    # Create a DataFrame for the current sector\n",
        "    sector_df = pd.DataFrame({'Date': data['dates'], 'Gewichtung (%)': data['weights']})\n",
        "\n",
        "    # Convert the 'Date' column to datetime, invalid parsing will be set as NaT\n",
        "    sector_df['Date'] = pd.to_datetime(sector_df['Date'], errors='coerce')\n",
        "\n",
        "    # Drop rows with NaT values in the 'Date' column\n",
        "    sector_df = sector_df.dropna(subset=['Date'])\n",
        "\n",
        "    # Sort the DataFrame by date\n",
        "    sector_df = sector_df.sort_values('Date')\n",
        "\n",
        "    # Plot the data for the current sector\n",
        "    plt.plot(sector_df['Date'], sector_df['Gewichtung (%)'], marker='o', markersize=5, label=sector)\n",
        "\n",
        "plt.title(\"Total Gewichtung (%) Over Time by Sector\")\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Total Gewichtung (%)')\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "plt.grid(True)\n",
        "# create a unique filename based on the filters\n",
        "filters_hash = hashlib.md5(\"sector_analysis\".encode()).hexdigest()\n",
        "plt.savefig(os.path.join(output_dir, f'gewichtung_by_sector_{filters_hash}.png'), dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "# Plot the data using plotly\n",
        "plotly_data = []\n",
        "for sector, data in sector_entries.items():\n",
        "    for date, weight in zip(data['dates'], data['weights']):\n",
        "        plotly_data.append({'Date': date, 'Gewichtung (%)': weight, 'Sector': sector})\n",
        "\n",
        "plotly_df = pd.DataFrame(plotly_data)\n",
        "\n",
        "# Convert the 'Date' column to datetime\n",
        "plotly_df['Date'] = pd.to_datetime(plotly_df['Date'], errors='coerce')\n",
        "\n",
        "# Drop rows with NaT values in the 'Date' column\n",
        "plotly_df = plotly_df.dropna(subset=['Date'])\n",
        "\n",
        "# Sort the DataFrame by date\n",
        "plotly_df = plotly_df.sort_values('Date')\n",
        "\n",
        "# Create the Plotly line chart\n",
        "fig = px.line(plotly_df, x='Date', y='Gewichtung (%)', color='Sector', title=\"Total Gewichtung (%) Over Time by Sector\",\n",
        "              category_orders={'Sector': sorted(plotly_df['Sector'].unique())})\n",
        "\n",
        "# Save the Plotly chart as an HTML file\n",
        "output_file = os.path.join(output_dir, f'gewichtung_by_sector_{filters_hash}.html')\n",
        "fig.write_html(output_file)\n",
        "\n",
        "print(f\"Interactive Plotly chart saved to {output_file}\")"
      ],
      "id": "f2351ef627924e3",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-16T07:59:08.827882Z",
          "start_time": "2025-05-16T07:59:03.559358Z"
        }
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Identify the latest date in the dataset\n",
        "latest_stichtag = max(df_by_stichtag.keys(), key=lambda x: pd.to_datetime(x, format='%Y%m%d'))\n",
        "\n",
        "# Filter the data for the latest date\n",
        "latest_df = df_by_stichtag[latest_stichtag]\n",
        "\n",
        "# Group the data by country and get the top 10 entries by \"Gewichtung (%)\" for each country\n",
        "top_10_by_country = latest_df.groupby('Standort').apply(lambda x: x.nlargest(50, 'Gewichtung (%)')).reset_index(drop=True)\n",
        "\n",
        "# Plot the data\n",
        "plt.figure(figsize=(14, 10))\n",
        "for country in top_10_by_country['Standort'].unique():\n",
        "    country_df = top_10_by_country[top_10_by_country['Standort'] == country]\n",
        "    plt.barh(country_df['Name'], country_df['Gewichtung (%)'], label=country)\n",
        "\n",
        "plt.title(f'Top 50 \"Name\" by \"Gewichtung (%)\" for Each Country on {latest_stichtag}')\n",
        "plt.xlabel('Gewichtung (%)')\n",
        "plt.ylabel('Name')\n",
        "plt.legend(title='Country', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(output_dir, f'top_50_by_country_{latest_stichtag}.png'), dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ],
      "id": "cb96a3061affcee5",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-16T07:59:09.110370Z",
          "start_time": "2025-05-16T07:59:08.961313Z"
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import hashlib\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "\n",
        "# Identify the latest date in the dataset\n",
        "latest_stichtag = max(df_by_stichtag.keys(), key=lambda x: pd.to_datetime(x, format='%Y%m%d'))\n",
        "\n",
        "# Filter the data for the latest date\n",
        "latest_df = df_by_stichtag[latest_stichtag]\n",
        "\n",
        "# Group the data by country and get the top 10 entries by \"Gewichtung (%)\" for each country\n",
        "top_10_by_country = latest_df.groupby('Standort').apply(lambda x: x.nlargest(50, 'Gewichtung (%)')).reset_index(drop=True)\n",
        "\n",
        "# Create a DataFrame for Plotly\n",
        "plotly_data = []\n",
        "for country in top_10_by_country['Standort'].unique():\n",
        "    country_df = top_10_by_country[top_10_by_country['Standort'] == country]\n",
        "    for _, row in country_df.iterrows():\n",
        "        plotly_data.append({'Name': row['Name'], 'Gewichtung (%)': row['Gewichtung (%)'], 'Country': country})\n",
        "\n",
        "plotly_df = pd.DataFrame(plotly_data)\n",
        "\n",
        "# Create the Plotly bar chart\n",
        "fig = px.bar(plotly_df, x='Gewichtung (%)', y='Name', color='Country', orientation='h', title=f'Top 50 \"Name\" by \"Gewichtung (%)\" for Each Country on {latest_stichtag}')\n",
        "\n",
        "# Save the Plotly chart as an HTML file\n",
        "filters_hash = hashlib.md5(\"top_50_by_country\".encode()).hexdigest()\n",
        "output_file = os.path.join(output_dir, f'top_50_by_country_{latest_stichtag}_{filters_hash}.html')\n",
        "fig.write_html(output_file)\n",
        "\n",
        "print(f\"Interactive Plotly chart saved to {output_file}\")"
      ],
      "id": "4406f76109dfb3a",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-16T08:01:00.650485Z",
          "start_time": "2025-05-16T07:59:09.131214Z"
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import hashlib\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "\n",
        "# Create a dictionary to store the dates and corresponding \"Gewichtung (%)\" values for each Name\n",
        "name_entries = {}\n",
        "\n",
        "# Iterate over the DataFrames to extract the \"Gewichtung (%)\" values for each Name\n",
        "for date, df in df_by_stichtag.items():\n",
        "    for name in df['Name'].unique():\n",
        "        if name not in name_entries:\n",
        "            name_entries[name] = {'dates': [], 'weights': []}\n",
        "\n",
        "        # Get the \"Gewichtung (%)\" for the current Name\n",
        "        weight = df[df['Name'] == name]['Gewichtung (%)'].sum()\n",
        "\n",
        "        name_entries[name]['dates'].append(date)\n",
        "        name_entries[name]['weights'].append(weight)\n",
        "\n",
        "# Plot the data using matplotlib\n",
        "plt.figure(figsize=(12, 8))\n",
        "for name, data in name_entries.items():\n",
        "    # Create a DataFrame for the current Name\n",
        "    name_df = pd.DataFrame({'Date': data['dates'], 'Gewichtung (%)': data['weights']})\n",
        "\n",
        "    # Convert the 'Date' column to datetime, invalid parsing will be set as NaT\n",
        "    name_df['Date'] = pd.to_datetime(name_df['Date'], errors='coerce')\n",
        "\n",
        "    # Drop rows with NaT values in the 'Date' column\n",
        "    name_df = name_df.dropna(subset=['Date'])\n",
        "\n",
        "    # Sort the DataFrame by date\n",
        "    name_df = name_df.sort_values('Date')\n",
        "\n",
        "    # Plot the data for the current Name\n",
        "    plt.plot(name_df['Date'], name_df['Gewichtung (%)'], marker='o', markersize=2, label=name)\n",
        "\n",
        "plt.title(\"Gewichtung (%) Over Time for Each Name\")\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Gewichtung (%)')\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "plt.grid(True)\n",
        "# create a unique filename based on the filters\n",
        "filters_hash = hashlib.md5(\"name_analysis\".encode()).hexdigest()\n",
        "plt.savefig(os.path.join(output_dir, f'gewichtung_by_name_{filters_hash}.png'), dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "# Plot the data using plotly\n",
        "plotly_data = []\n",
        "for name, data in name_entries.items():\n",
        "    for date, weight in zip(data['dates'], data['weights']):\n",
        "        plotly_data.append({'Date': date, 'Gewichtung (%)': weight, 'Name': name})\n",
        "\n",
        "plotly_df = pd.DataFrame(plotly_data)\n",
        "\n",
        "# Convert the 'Date' column to datetime\n",
        "plotly_df['Date'] = pd.to_datetime(plotly_df['Date'], errors='coerce')\n",
        "\n",
        "# Drop rows with NaT values in the 'Date' column\n",
        "plotly_df = plotly_df.dropna(subset=['Date'])\n",
        "\n",
        "# Sort the DataFrame by date\n",
        "plotly_df = plotly_df.sort_values('Date')\n",
        "\n",
        "# Create the Plotly line chart\n",
        "fig = px.line(plotly_df, x='Date', y='Gewichtung (%)', color='Name', title=\"Gewichtung (%) Over Time for Each Name\",\n",
        "              category_orders={'Name': sorted(plotly_df['Name'].unique())})\n",
        "\n",
        "# Save the Plotly chart as an HTML file\n",
        "output_file = os.path.join(output_dir, f'gewichtung_by_name_LARGE_{filters_hash}.html')\n",
        "fig.write_html(output_file)\n",
        "\n",
        "print(f\"Interactive Plotly chart saved to {output_file}\")"
      ],
      "id": "fec96898d1d5a264",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-16T08:01:23.586899Z",
          "start_time": "2025-05-16T08:01:13.212654Z"
        }
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import os\n",
        "\n",
        "# Aggregate the data by Standort and date\n",
        "country_weights = []\n",
        "\n",
        "for date, df in df_by_stichtag.items():\n",
        "    aggregated = df.groupby('Standort')['Gewichtung (%)'].sum().reset_index()\n",
        "    aggregated['Date'] = date\n",
        "    country_weights.append(aggregated)\n",
        "\n",
        "# Combine all dates into a single DataFrame\n",
        "country_weights_df = pd.concat(country_weights)\n",
        "\n",
        "# Convert the 'Date' column to datetime\n",
        "country_weights_df['Date'] = pd.to_datetime(country_weights_df['Date'], format='%Y%m%d')\n",
        "\n",
        "# Sort the DataFrame by date\n",
        "country_weights_df = country_weights_df.sort_values('Date')\n",
        "\n",
        "# Define a fixed color mapping for each Standort\n",
        "unique_standorts = country_weights_df['Standort'].unique()\n",
        "color_mapping = {standort: f'rgba({i * 30 % 255}, {i * 60 % 255}, {i * 90 % 255}, 1)' for i, standort in enumerate(unique_standorts)}\n",
        "\n",
        "# Create the animated bar chart with fixed colors\n",
        "fig = px.bar(\n",
        "    country_weights_df,\n",
        "    x='Gewichtung (%)',\n",
        "    y='Standort',\n",
        "    color='Standort',\n",
        "    orientation='h',\n",
        "    animation_frame=country_weights_df['Date'].dt.strftime('%Y-%m-%d'),\n",
        "    title='All Countries by Weight Over Time',\n",
        "    labels={'Gewichtung (%)': 'Weight (%)', 'Standort': 'Country'},\n",
        "    range_x=[0, 100],  # Set the x-axis range to be constant from 0 to 100\n",
        "    color_discrete_map=color_mapping,  # Apply the fixed color mapping\n",
        "    category_orders={'Standort': unique_standorts}\n",
        ")\n",
        "\n",
        "# Save the animation as an HTML file\n",
        "filters_hash = hashlib.md5(\"all_countries_by_gewichtung_time_animation\".encode()).hexdigest()\n",
        "output_file = os.path.join(output_dir, f'all_countries_by_gewichtung_time_animation_{filters_hash}.html')\n",
        "fig.write_html(output_file)\n",
        "\n",
        "print(f\"Interactive animation saved to {output_file}\")\n",
        "fig.show()"
      ],
      "id": "9e32fd3e2fda01d7",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-16T08:01:26.459230Z",
          "start_time": "2025-05-16T08:01:26.366443Z"
        }
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import os\n",
        "import hashlib\n",
        "\n",
        "# Identify the latest and second latest months\n",
        "sorted_dates = sorted(df_by_stichtag.keys(), key=lambda x: pd.to_datetime(x, format='%Y%m%d'))\n",
        "latest_month = sorted_dates[-1]\n",
        "previous_month = sorted_dates[-2]\n",
        "\n",
        "# Get the DataFrames for the latest and previous months\n",
        "latest_df = df_by_stichtag[latest_month]\n",
        "previous_df = df_by_stichtag[previous_month]\n",
        "\n",
        "# Add the country to the ticker in brackets\n",
        "merged_df = pd.merge(\n",
        "    previous_df[['Name', 'Anlageklasse', 'Gewichtung (%)', 'Standort']],\n",
        "    latest_df[['Name', 'Anlageklasse', 'Gewichtung (%)', 'Standort']],\n",
        "    on=['Name', 'Anlageklasse', 'Standort'],\n",
        "    suffixes=('_previous', '_latest')\n",
        ")\n",
        "\n",
        "# Calculate the percentage change\n",
        "merged_df['Percentage Change (%)'] = ((merged_df['Gewichtung (%)_latest'] - merged_df['Gewichtung (%)_previous']) /\n",
        "                                      merged_df['Gewichtung (%)_previous']) * 100\n",
        "\n",
        "# Group by \"Anlageklasse\" and get the top 20 winners and losers for each group\n",
        "top_20_winners_per_anlageklasse = merged_df.groupby('Anlageklasse', group_keys=False).apply(\n",
        "    lambda x: x.nlargest(20, 'Percentage Change (%)')\n",
        ")\n",
        "top_20_losers_per_anlageklasse = merged_df.groupby('Anlageklasse', group_keys=False).apply(\n",
        "    lambda x: x.nsmallest(20, 'Percentage Change (%)')\n",
        ")\n",
        "\n",
        "# Combine winners and losers into a single DataFrame\n",
        "top_20_combined = pd.concat([top_20_winners_per_anlageklasse, top_20_losers_per_anlageklasse])\n",
        "top_20_combined['Category'] = ['Winner' if x > 0 else 'Loser' for x in top_20_combined['Percentage Change (%)']]\n",
        "\n",
        "# Add the country to the ticker in brackets\n",
        "top_20_combined['Name'] = top_20_combined.apply(\n",
        "    lambda row: f\"{row['Name']} ({row['Standort']})\", axis=1\n",
        ")\n",
        "\n",
        "# Filter out changes lower than 1%\n",
        "top_20_combined = top_20_combined[abs(top_20_combined['Percentage Change (%)']) >= 1]\n",
        "\n",
        "# Filter out Anlageklasse groups with no values\n",
        "top_20_combined = top_20_combined[top_20_combined['Anlageklasse'].notna()]\n",
        "\n",
        "# Create the Plotly bar chart\n",
        "fig = px.bar(\n",
        "    top_20_combined,\n",
        "    x='Percentage Change (%)',\n",
        "    y='Name',\n",
        "    color='Category',\n",
        "    facet_col='Anlageklasse',\n",
        "    orientation='h',\n",
        "    title=f\"Top 20 Winners and Losers per Anlageklasse ({previous_month} to {latest_month})\",\n",
        "    labels={'Percentage Change (%)': 'Percentage Change (%)', 'Name': 'Ticker'},\n",
        "    color_discrete_map={'Winner': 'green', 'Loser': 'red'}\n",
        ")\n",
        "\n",
        "# Update the layout to use a logarithmic scale for the x-axis\n",
        "fig.update_layout(xaxis_type='log')\n",
        "\n",
        "# Save the Plotly chart as an HTML file\n",
        "filters_hash = hashlib.md5(\"top_20_winners_losers_per_anlageklasse\".encode()).hexdigest()\n",
        "output_file = os.path.join(output_dir, f'top_20_winners_losers_per_anlageklasse_{latest_month}_{filters_hash}.html')\n",
        "fig.write_html(output_file)\n",
        "\n",
        "print(f\"Interactive HTML chart saved to {output_file}\")"
      ],
      "id": "86101e5bb4987c5e",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-16T08:01:26.674487Z",
          "start_time": "2025-05-16T08:01:26.538959Z"
        }
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import os\n",
        "import hashlib\n",
        "\n",
        "# Identify the latest and second latest months\n",
        "sorted_dates = sorted(df_by_stichtag.keys(), key=lambda x: pd.to_datetime(x, format='%Y%m%d'))\n",
        "latest_month = sorted_dates[-1]\n",
        "previous_month = sorted_dates[-2]\n",
        "\n",
        "# Get the DataFrames for the latest and previous months\n",
        "latest_df = df_by_stichtag[latest_month]\n",
        "previous_df = df_by_stichtag[previous_month]\n",
        "\n",
        "# Filter for \"Aktien\" in the \"Anlageklasse\" column\n",
        "latest_df = latest_df[latest_df['Anlageklasse'] == 'Aktien']\n",
        "previous_df = previous_df[previous_df['Anlageklasse'] == 'Aktien']\n",
        "\n",
        "# Merge the two DataFrames on 'Name', 'Standort', and 'Anlageklasse' to compare weights\n",
        "merged_df = pd.merge(\n",
        "    previous_df[['Name', 'Standort', 'Gewichtung (%)']],\n",
        "    latest_df[['Name', 'Standort', 'Gewichtung (%)']],\n",
        "    on=['Name', 'Standort'],\n",
        "    suffixes=('_previous', '_latest')\n",
        ")\n",
        "\n",
        "# Calculate the percentage change\n",
        "merged_df['Percentage Change (%)'] = ((merged_df['Gewichtung (%)_latest'] - merged_df['Gewichtung (%)_previous']) /\n",
        "                                      merged_df['Gewichtung (%)_previous']) * 100\n",
        "\n",
        "# Group by \"Standort\" and calculate the mean percentage change for each country\n",
        "grouped_df = merged_df.groupby('Standort', as_index=False)['Percentage Change (%)'].mean()\n",
        "\n",
        "# Create the Plotly bar chart\n",
        "fig = px.bar(\n",
        "    grouped_df,\n",
        "    x='Standort',\n",
        "    y='Percentage Change (%)',\n",
        "    title=f\"Percentage Change of 'Aktien' by Country ({previous_month} to {latest_month})\",\n",
        "    labels={'Standort': 'Country', 'Percentage Change (%)': 'Average Percentage Change (%)'},\n",
        "    color='Standort',\n",
        "    color_discrete_sequence=px.colors.qualitative.Set2\n",
        ")\n",
        "\n",
        "# Save the Plotly chart as an HTML file\n",
        "filters_hash = hashlib.md5(\"aktien_percentage_change_by_country\".encode()).hexdigest()\n",
        "output_file = os.path.join(output_dir, f'aktien_percentage_change_by_country_{latest_month}_{filters_hash}.html')\n",
        "fig.write_html(output_file)\n",
        "\n",
        "print(f\"Interactive HTML chart saved to {output_file}\")\n",
        "fig.show()"
      ],
      "id": "b5f27c968eb1b979",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-16T08:01:27.011950Z",
          "start_time": "2025-05-16T08:01:26.894074Z"
        }
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import os\n",
        "import hashlib\n",
        "\n",
        "# Identify the latest and second latest months\n",
        "sorted_dates = sorted(df_by_stichtag.keys(), key=lambda x: pd.to_datetime(x, format='%Y%m%d'))\n",
        "latest_month = sorted_dates[-1]\n",
        "previous_month = sorted_dates[-2]\n",
        "\n",
        "# Get the DataFrames for the latest and previous months\n",
        "latest_df = df_by_stichtag[latest_month]\n",
        "previous_df = df_by_stichtag[previous_month]\n",
        "\n",
        "# Filter for \"Geldmarkt\" in the \"Anlageklasse\" column\n",
        "latest_df = latest_df[latest_df['Anlageklasse'] == 'Geldmarkt']\n",
        "previous_df = previous_df[previous_df['Anlageklasse'] == 'Geldmarkt']\n",
        "\n",
        "# Merge the two DataFrames on 'Name', 'Standort', and 'Anlageklasse' to compare weights\n",
        "merged_df = pd.merge(\n",
        "    previous_df[['Name', 'Standort', 'Gewichtung (%)']],\n",
        "    latest_df[['Name', 'Standort', 'Gewichtung (%)']],\n",
        "    on=['Name', 'Standort'],\n",
        "    suffixes=('_previous', '_latest')\n",
        ")\n",
        "\n",
        "# Calculate the percentage change\n",
        "merged_df['Percentage Change (%)'] = ((merged_df['Gewichtung (%)_latest'] - merged_df['Gewichtung (%)_previous']) /\n",
        "                                      merged_df['Gewichtung (%)_previous']) * 100\n",
        "\n",
        "# Group by \"Standort\" and calculate the mean percentage change for each country\n",
        "grouped_df = merged_df.groupby('Standort', as_index=False)['Percentage Change (%)'].mean()\n",
        "\n",
        "# Create the Plotly bar chart\n",
        "fig = px.bar(\n",
        "    grouped_df,\n",
        "    x='Standort',\n",
        "    y='Percentage Change (%)',\n",
        "    title=f\"Percentage Change of 'Geldmarkt' by Country ({previous_month} to {latest_month})\",\n",
        "    labels={'Standort': 'Country', 'Percentage Change (%)': 'Average Percentage Change (%)'},\n",
        "    color='Standort',\n",
        "    color_discrete_sequence=px.colors.qualitative.Set2\n",
        ")\n",
        "\n",
        "# Save the Plotly chart as an HTML file\n",
        "filters_hash = hashlib.md5(\"geldmarkt_percentage_change_by_country\".encode()).hexdigest()\n",
        "output_file = os.path.join(output_dir, f'geldmarkt_percentage_change_by_country_{latest_month}_{filters_hash}.html')\n",
        "fig.write_html(output_file)\n",
        "\n",
        "print(f\"Interactive HTML chart saved to {output_file}\")\n",
        "fig.show()"
      ],
      "id": "1260814e6f6f1cdc",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "",
      "id": "9b224c2bd628bcdd"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat": 5,
  "nbformat_minor": 9
}
